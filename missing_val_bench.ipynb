{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark for RF w/Missing Value support\n",
    "\n",
    "#### Sys stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Linux-3.12.18-enst.1-x86_64-with-debian-7.9\n",
      "At host \"tsilinuxd98\" with 8 cores. Current Dir - /cal/homes/vrajagopalan/raghav/miss_val_bench\n",
      "\n",
      "sklearn 0.18.dev0 in branch \"missing_values_rf\", (ec3f590-ENH Fix missed line; More cleanup; Use named constants)\n",
      "@ ['/tsi/doctorants/raghav/anaconda/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn']\n",
      "\n",
      "np v1.10.4 - scipy v0.17.0 \n",
      "IPython v4.0.3 - Python 2.7.11 :: Anaconda 2.5.0 (64-bit)\n",
      "@ /tsi/doctorants/raghav/anaconda/anaconda3/envs/python2/bin/python\n"
     ]
    }
   ],
   "source": [
    "# To keep track of the machine this script is run in\n",
    "import IPython; import sklearn, numpy as np, scipy; from ast import literal_eval\n",
    "import platform;\n",
    "\n",
    "CURR_IPYTHON_VERSION = IPython.__version__\n",
    "PYTHON_INPT = literal_eval(IPython.sys_info())['sys_executable']\n",
    "SKVERSION = sklearn.__version__; SCVERSION = scipy.__version__; NPVERSION = np.__version__\n",
    "print \"Running on %s\" % platform.platform()\n",
    "!echo -e \"At host \\\"$(hostname)\\\" with $(nproc) cores. Current Dir - $(pwd)\\n\"\n",
    "!echo -n \"sklearn $SKVERSION \"\n",
    "!echo -n \"in branch \\\"\"\n",
    "!echo -n \"$(git --git-dir \"$SCIKIT_LEARN_PATH\"/.git rev-parse --abbrev-ref HEAD)\\\", \"\n",
    "!echo \"($(git --git-dir \"$SCIKIT_LEARN_PATH\"/.git log --pretty=format:'%h-%s' -n 1))\"\n",
    "print \"@ %s\\n\" % str(sklearn.__path__)\n",
    "!echo -e -n \"np v$NPVERSION - scipy v$SCVERSION \\nIPython v$CURR_IPYTHON_VERSION - \"\n",
    "!echo -n \"$($PYTHON_INPT --version)\"\n",
    "!echo \"@ $PYTHON_INPT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from get_graph import get_graph\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from xgbrf import XGBRFClassifier\n",
    "from value_dropper import drop_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use all the cores\n",
    "n_jobs = -1\n",
    "n_estimators = 50\n",
    "imputation_strategy = 'mean'\n",
    "bootstrap = False\n",
    "criterion = 'gini'\n",
    "missing_values = 'NaN'\n",
    "random_state = 42\n",
    "max_depth = 20\n",
    "\n",
    "# To compute max_features, we need the shape of data before\n",
    "# max_features = int(round(sqrt(data.shape[1])))\n",
    "# max_feature_fraction = float(max_features) / data.shape[1]\n",
    "max_feature_fraction = 0.8\n",
    "\n",
    "# Use 3 iterations of SSS\n",
    "cv = StratifiedShuffleSplit(n_iter=3, test_size=0.1,\n",
    "                            random_state=42)\n",
    "\n",
    "\n",
    "# THE ESTIMATORS\n",
    "# 0. RF w/MV\n",
    "rf_miss_val = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                     criterion=criterion,\n",
    "                                     max_features=max_feature_fraction,\n",
    "                                     max_depth=max_depth,\n",
    "                                     bootstrap=bootstrap,\n",
    "                                     missing_values=missing_values,\n",
    "                                     n_jobs=n_jobs,\n",
    "                                     random_state=random_state)\n",
    "\n",
    "# 1. Imputation ---> RF\n",
    "rf_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                      missing_values=missing_values)), \n",
    "                      ('rf', RandomForestClassifier(\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 criterion=criterion,\n",
    "                                 max_features=max_feature_fraction,\n",
    "                                 max_depth=max_depth,\n",
    "                                 bootstrap=bootstrap,\n",
    "                                 # Don't allow missing, we've imputed them\n",
    "                                 missing_values=None,  \n",
    "                                 n_jobs=n_jobs,\n",
    "                                 random_state=random_state))])\n",
    "\n",
    "# 2. estimator to bench {Missing Data replaced with a MAX val + RF}\n",
    "rf_max_min = RandomForestClassifier(\n",
    "                 n_estimators=n_estimators,\n",
    "                 criterion=criterion,\n",
    "                 max_features=max_feature_fraction,\n",
    "                 max_depth=max_depth,\n",
    "                 bootstrap=True,\n",
    "                 missing_values=None,\n",
    "                 n_jobs=n_jobs,\n",
    "                 random_state=42)\n",
    "\n",
    "# 3. Imputation ---> DummyClassifier\n",
    "dummy_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('dum', DummyClassifier())])\n",
    "\n",
    "# 4. Imputation ---> LogisticRegressionCV\n",
    "logit_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('log', LogisticRegressionCV(\n",
    "                                     n_jobs=n_jobs,\n",
    "                                     random_state=random_state))])\n",
    "\n",
    "# 5. Imputation --> XGBoost's Gradient Boosting Clf\n",
    "xgboost_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                           missing_values=missing_values)), \n",
    "                           ('xgb', XGBClassifier(\n",
    "                                       # Don't allow missing, we've imputed them\n",
    "                                       n_estimators=n_estimators,\n",
    "                                       nthread=n_jobs,\n",
    "                                       seed=random_state))])\n",
    "\n",
    "# 6. XGBoost's Gradient Boosting Clf w/missing values handled inherently\n",
    "xgboost_miss_val = XGBClassifier(n_estimators=n_estimators,\n",
    "                                 missing=np.nan,  # XGBoost doesn't accept \"NaN\"\n",
    "                                 nthread=n_jobs,\n",
    "                                 seed=random_state)\n",
    "\n",
    "# 7. Imputation --> XGBoost's RF (using num_parallel_tree)\n",
    "xgbrf_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('xgb', XGBRFClassifier(\n",
    "                                     n_estimators=n_estimators,\n",
    "                                     # Fraction of features to take for each tree\n",
    "                                     # Take sqrt(n_features) / n_features\n",
    "                                     colsample_bytree=max_feature_fraction,\n",
    "                                     max_depth=max_depth,\n",
    "                                     # No Bootstrapping, choose all samples exactly once\n",
    "                                     num_boost_round=1,\n",
    "                                     subsample=1,  \n",
    "                                     nthread=n_jobs,\n",
    "                                     seed=random_state))])\n",
    "\n",
    "# 8. XGBoost's RF (using num_parallel_tree) w/missing values handled inherently\n",
    "xgbrf_miss_val = XGBRFClassifier(\n",
    "                       n_estimators=n_estimators,\n",
    "                       # Fraction of features to take for each tree\n",
    "                       # Take sqrt(n_features) / n_features\n",
    "                       colsample_bytree=max_feature_fraction,\n",
    "                       max_depth=max_depth,\n",
    "                       # No Bootstrapping, choose all samples exactly once\n",
    "                       missing=np.nan,\n",
    "                       num_boost_round=1,\n",
    "                       subsample=1,\n",
    "                       nthread=n_jobs,\n",
    "                       seed=random_state)\n",
    "\n",
    "# 9. RF w/MV w/bootstrap\n",
    "rf_miss_val_btstrp = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                            bootstrap=True,\n",
    "                                            missing_values=missing_values,\n",
    "                                            max_features=max_feature_fraction,\n",
    "                                            max_depth=max_depth,\n",
    "                                            n_jobs=n_jobs,\n",
    "                                            random_state=random_state)\n",
    "\n",
    "# 10. IMP + RF w/o MV w/bootstrap\n",
    "rf_impute_btstrp = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                             missing_values=missing_values)), \n",
    "                             ('rf', RandomForestClassifier(\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        bootstrap=True,\n",
    "                                        max_features=max_feature_fraction,\n",
    "                                        max_depth=max_depth,\n",
    "                                        # Don't allow missing, we've imputed them\n",
    "                                        missing_values=None,  \n",
    "                                        n_jobs=n_jobs,\n",
    "                                        random_state=random_state))])\n",
    "\n",
    "# 11. IMP + RF w/o MV w/bootstrap\n",
    "\n",
    "rf_impute_btstrp = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                             missing_values=missing_values)), \n",
    "                             ('rf', RandomForestClassifier(\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        bootstrap=True,\n",
    "                                        max_features=max_feature_fraction,\n",
    "                                        max_depth=max_depth,\n",
    "                                        # Don't allow missing, we've imputed them\n",
    "                                        missing_values=None,  \n",
    "                                        n_jobs=n_jobs,\n",
    "                                        random_state=random_state))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 % of values missing\n",
      "The shape of the entire dataset - (581012, 54); Target - (581012,)\n",
      "The shape of the subsampled dataset - (14526, 54)\n",
      "\n",
      "The maximum data value : 50098084.00 and minimum value : 23716.00\n",
      "\n",
      "Labels -\t[1 2 3 4 5 6 7]\n",
      "Label counts -\t[5285 7108  873   64  236  439  521]\n",
      "\n",
      "For MNAR case, the labels to correlate are - [1]\n",
      "\n",
      "The histogram of the label counts\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAE4CAYAAAAuFPo7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe57ea9fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset_names = [\"covtype\", \"iris\", \"make_classification\"]\n",
    "\n",
    "dataset_name = all_dataset_names[0]\n",
    "\n",
    "if dataset_name == \"covtype\":\n",
    "    dataset = fetch_covtype()\n",
    "    data, target = dataset.data, dataset.target\n",
    "    subsample_dataset = True\n",
    "    make_binary = False\n",
    "    subsample_interval = 40\n",
    "\n",
    "elif dataset_name == \"iris\":\n",
    "    dataset = load_iris()\n",
    "    data, target = dataset.data, dataset.target\n",
    "    subsample_dataset = False\n",
    "    make_binary = False\n",
    "\n",
    "elif dataset_name == \"make_classification\":\n",
    "    data, target = make_classification(n_samples=10000, n_features=8,\n",
    "                                       n_informative=6, n_redundant=2,\n",
    "                                       n_classes=8,\n",
    "                                       n_clusters_per_class=2,\n",
    "                                       random_state=42)\n",
    "    subsample_dataset = False\n",
    "    make_binary = False\n",
    "\n",
    "# densify\n",
    "if scipy.sparse.issparse(data):\n",
    "    print \"Data is sparse! Attempting densification\"\n",
    "    data = data.toarray()\n",
    "\n",
    "# Initially we have no missing\n",
    "print \"%0.2f %% of values missing\" % (np.mean(np.isnan(target))*100)\n",
    "\n",
    "print \"The shape of the entire dataset - %s; Target - %s\" % (str(data.shape), str(target.shape))\n",
    "if subsample_dataset:\n",
    "    #Subsample the data\n",
    "    data, target = data[::subsample_interval], target[::subsample_interval]\n",
    "    print \"The shape of the subsampled dataset - %s\" % str(data.shape)\n",
    "    print\n",
    "\n",
    "if make_binary:\n",
    "    mask = target <= 2\n",
    "    data, target = data[mask], target[mask]\n",
    "    print \"The shape of the binary dataset - %s\" % str(data.shape)\n",
    "    print\n",
    "\n",
    "# Set the data_max and data_min vars\n",
    "data_max = data.max() ** 2\n",
    "data_min = data.min() ** 2\n",
    "\n",
    "\n",
    "print \"The maximum data value : %0.2f and minimum value : %0.2f\" % (data_max, data_min)\n",
    "print\n",
    "\n",
    "labels = np.unique(target)\n",
    "print \"Labels -\\t\", labels\n",
    "label_counts = np.bincount(target)[-len(labels):]\n",
    "print \"Label counts -\\t\", label_counts\n",
    "print\n",
    "\n",
    "labels_to_correlate_for_mnar = [1]\n",
    "\n",
    "print \"For MNAR case, the labels to correlate are - %s\" % labels_to_correlate_for_mnar\n",
    "print\n",
    "\n",
    "print \"The histogram of the label counts\"\n",
    "\n",
    "old_fig_size = plt.rcParams['figure.figsize'][:]\n",
    "plt.rcParams['figure.figsize'][:] = [5, 5]\n",
    "plt.bar(labels+0, label_counts, color='k', align='center')\n",
    "plt.xlim([np.min(labels)-0.5, np.max(labels)+0.5])\n",
    "plt.rcParams['figure.figsize'][:] = old_fig_size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selectively Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the plot legend\n",
    "est_labels = [\n",
    "    'RF w/MV',                                # 0\n",
    "    'IMP + RF',                               # 1\n",
    "    'Missing max replaced + RF',              # 2\n",
    "    'IMP + Dummy',                            # 3\n",
    "    'IMP + Logit',                            # 4\n",
    "    'XGB w/MV handled internally',            # 5\n",
    "    'IMP + XGB',                              # 6\n",
    "    'XGBs RF w/MV handled internally',        # 7\n",
    "    'IMP + XGBs RF',                          # 8\n",
    "    'RF w/MV with bootstrap True',            # 9\n",
    "    'IMP + RF w/o MV with bootstrap True',    # 10\n",
    "]  \n",
    "\n",
    "# The estimators/techniques to run for benchmarking\n",
    "bench_mask = [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "]\n",
    "\n",
    "n_experiments_per_plot = 30\n",
    "min_label_correlation, max_label_correlation = 0., 1  # 1 is fully MNAR, which is not possible 0.9 is noisy MNAR\n",
    "                                                       # plus 1 performs almost as good as our impl, while\n",
    "                                                       # a label correlation of 0.9 does not\n",
    "n_correlation_levels = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some baseline scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (RF) is %0.8f'\n",
    "#       % cross_val_score(rf_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (xgboost) is %0.8f'\n",
    "#       % cross_val_score(xgboost_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (xgboost) is %0.8f'\n",
    "#       % cross_val_score(xgbrf_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bench mask is [7, 8, 9, 10]\n",
      "0.363830373124\n",
      "The label correlations [ 0.   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1. ] \n",
      "Labels correlated with - [1]\n",
      "Label correlation - 0.00\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 0/0\n",
      "Missing fraction - (Expected - 0.0000, Actual - 0.0000)\n",
      "Fraction of samples missing when label == 1 - 0.0000\n",
      "Fraction of samples missing when label != 1 - 0.0000\n",
      "-------------------------------------------------------\n",
      "XGBoosts RF  w/miss val handled internally completed in 12.95 s with a mean score of 0.7949\n",
      "Imp + XGBoosts RF completed in 12.73 s with a mean score of 0.7949\n",
      "\n",
      "RF w/MV w/bootstrap completed in 3.30 s with a mean score of 0.8181\n",
      "IMP + RF w/bootstrap completed in 3.16 s with a mean score of 0.8181\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 0/21638\n",
      "Missing fraction - (Expected - 0.0276, Actual - 0.0276)\n",
      "Fraction of samples missing when label == 1 - 0.0277\n",
      "Fraction of samples missing when label != 1 - 0.0275\n",
      "-------------------------------------------------------\n",
      "XGBoosts RF  w/miss val handled internally completed in 23.03 s with a mean score of 0.7772\n",
      "Imp + XGBoosts RF completed in 13.39 s with a mean score of 0.7798\n",
      "\n",
      "RF w/MV w/bootstrap completed in 4.73 s with a mean score of 0.7910\n",
      "IMP + RF w/bootstrap completed in 3.82 s with a mean score of 0.7942\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 0/21639\n",
      "Missing fraction - (Expected - 0.0552, Actual - 0.0552)\n",
      "Fraction of samples missing when label == 1 - 0.0553\n",
      "Fraction of samples missing when label != 1 - 0.0551\n",
      "-------------------------------------------------------\n",
      "XGBoosts RF  w/miss val handled internally completed in 22.55 s with a mean score of 0.7619\n",
      "Imp + XGBoosts RF completed in 13.69 s with a mean score of 0.7662"
     ]
    }
   ],
   "source": [
    "print 'The bench mask is %s' % bench_mask\n",
    "\n",
    "missing_mask = np.zeros(data.shape, dtype=bool)\n",
    "labels = None\n",
    "\n",
    "label_1_fraction = np.mean(target==labels_to_correlate_for_mnar[0])\n",
    "print label_1_fraction\n",
    "\n",
    "label_correlations = np.linspace(min_label_correlation, max_label_correlation, n_correlation_levels)\n",
    "print 'The label correlations %s ' % label_correlations\n",
    "missing_fractions = list([(np.linspace(0, 0.80, n_experiments_per_plot) if label_correlation_i == 0\n",
    "                           # Label 1 accounts of only around 35% of the samples\n",
    "                           else np.linspace(0, 0.9 * label_1_fraction, n_experiments_per_plot))\n",
    "                          for label_correlation_i in label_correlations])\n",
    "\n",
    "rng = np.random.RandomState(random_state)\n",
    "                        \n",
    "n_samples, n_features = data.shape\n",
    "n_missing_fractions = list(map(len, missing_fractions))\n",
    "\n",
    "n_experiments = len(label_correlations) * sum(n_missing_fractions)\n",
    "\n",
    "# Intialize the scores and times with zeros\n",
    "rf_miss_val_scores = np.zeros(n_experiments)\n",
    "rf_impute_scores = np.zeros(n_experiments)\n",
    "rf_max_min_scores = np.zeros(n_experiments)\n",
    "dummy_impute_scores = np.zeros(n_experiments)\n",
    "logit_impute_scores = np.zeros(n_experiments)\n",
    "xgboost_impute_scores = np.zeros(n_experiments)\n",
    "xgboost_miss_val_scores = np.zeros(n_experiments)\n",
    "xgbrf_miss_val_scores = np.zeros(n_experiments)\n",
    "xgbrf_impute_scores = np.zeros(n_experiments)\n",
    "rf_miss_val_btstrp_scores = np.zeros(n_experiments)\n",
    "rf_impute_btstrp_scores = np.zeros(n_experiments)\n",
    "\n",
    "rf_miss_val_times = np.zeros(n_experiments)\n",
    "rf_impute_times = np.zeros(n_experiments)\n",
    "rf_max_min_times = np.zeros(n_experiments)\n",
    "dummy_impute_times = np.zeros(n_experiments)\n",
    "logit_impute_times = np.zeros(n_experiments)\n",
    "xgboost_impute_times = np.zeros(n_experiments)\n",
    "xgboost_miss_val_times = np.zeros(n_experiments)\n",
    "xgbrf_miss_val_times = np.zeros(n_experiments)\n",
    "xgbrf_impute_times = np.zeros(n_experiments)\n",
    "rf_miss_val_btstrp_times = np.zeros(n_experiments)\n",
    "rf_impute_btstrp_times = np.zeros(n_experiments)\n",
    "\n",
    "experiment_i = -1\n",
    "for i, label_correlation in enumerate(label_correlations):\n",
    "    labels = labels_to_correlate_for_mnar\n",
    "    print \"Labels correlated with - %s\" % str(labels)\n",
    "    print \"Label correlation - %0.2f\" % label_correlation\n",
    "    print\n",
    "    \n",
    "    X, y = data.copy(), target.copy()\n",
    "    missing_mask = np.zeros(X.shape, dtype=bool)\n",
    "        \n",
    "    for j, missing_fraction in enumerate(missing_fractions[i]):\n",
    "        print\n",
    "        print \"-------------------------------------------------------\"\n",
    "        \n",
    "        \"\"\"\n",
    "        # Old way of generating missing data --------------------------\n",
    "        rv = rng.randn(*X.shape)\n",
    "        rv = rng.randn(*X.shape)\n",
    "        thresh = np.sort(rv.ravel())[int(missing_fraction * n_samples * n_features)]\n",
    "        missing_mask += rv < thresh\n",
    "        if label_correlation == 1:  # MNAR\n",
    "            missing_mask[y!=labels[0]] = False  # Features should go missing only for y=1\n",
    "        X[missing_mask] = np.nan\n",
    "        # -------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate the missing values using the `drop_values` function\n",
    "        X, y, missing_mask, label = drop_values(\n",
    "            X, y,\n",
    "            missing_mask=missing_mask,\n",
    "            missing_fraction=missing_fraction,\n",
    "            # The MCAR-ness should not change\n",
    "            label_correlation=label_correlation,\n",
    "            # Persist the correlation with the same label\n",
    "            labels=labels,\n",
    "            return_missing_mask=True,\n",
    "            return_labels=True,\n",
    "            random_state=random_state,\n",
    "            )\n",
    "        \n",
    "        print (\"Missing fraction - (Expected - %0.4f, Actual - %0.4f)\"\n",
    "               % (missing_fraction, missing_mask.mean()))\n",
    "        print (\"Fraction of samples missing when label == %d - %0.4f\"\n",
    "               % (labels[0], missing_mask[y==labels[0]].mean()))\n",
    "        print (\"Fraction of samples missing when label != %d - %0.4f\"\n",
    "               % (labels[0], missing_mask[y!=labels[0]].mean()))\n",
    "        print \"-------------------------------------------------------\"\n",
    "        \n",
    "        experiment_i += 1\n",
    "        \n",
    "        # RF w/MV\n",
    "        if 0 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(rf_miss_val, X, y, cv=cv).mean())\n",
    "            rf_miss_val_times[experiment_i] = timer() - start\n",
    "            print (\"RF w/MV completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_miss_val_times[experiment_i],\n",
    "                      rf_miss_val_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + RF\n",
    "        if 1 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_impute_scores[experiment_i] = (\n",
    "                cross_val_score(rf_impute, X, y, cv=cv).mean())\n",
    "            rf_impute_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_impute_times[experiment_i],\n",
    "                      rf_impute_scores[experiment_i]))\n",
    "            print\n",
    "        \n",
    "        # X replaced + RF\n",
    "        if 2 in bench_mask:\n",
    "            # Replace X's nan with data_max/data_min\n",
    "            X[missing_mask] = data_max\n",
    "            start = timer()\n",
    "            rf_max_min_scores[experiment_i] = (\n",
    "                cross_val_score(rf_max_min, X, y, cv=cv).mean())\n",
    "            rf_max_min_times[experiment_i] = timer() - start\n",
    "            # Revert the change\n",
    "            X[missing_mask] = np.nan\n",
    "            print (\"Missing replaced + RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_max_min_times[experiment_i],\n",
    "                      rf_max_min_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + Dummy\n",
    "        if 3 in bench_mask:\n",
    "            start = timer()\n",
    "            dummy_impute_scores[experiment_i] = (\n",
    "                cross_val_score(dummy_impute, X, y, cv=cv).mean())\n",
    "            dummy_impute_times = timer() - start\n",
    "            print (\"IMP + Dummy completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (dummy_impute_times[experiment_i],\n",
    "                      dummy_impute_scores[experiment_i]))\n",
    "            print\n",
    "\n",
    "\n",
    "        # IMP + Logistic Regression\n",
    "        if 4 in bench_mask:\n",
    "            start = timer()\n",
    "            logit_impute_scores[experiment_i] = (\n",
    "                cross_val_score(logit_impute, X, y, cv=cv).mean())\n",
    "            logit_impute_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + Logit completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (logit_impute_times[experiment_i],\n",
    "                      logit_impute_scores[experiment_i]))\n",
    "            print\n",
    "\n",
    "        # XGB's GB w/MV\n",
    "        if 5 in bench_mask:\n",
    "            start = timer()\n",
    "            xgboost_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(xgboost_miss_val, X, y, cv=cv).mean())\n",
    "            xgboost_miss_val_times = timer() - start\n",
    "            print (\"XGBoost w/miss val handled internally completed in %0.2f s \"\n",
    "                   \"with a mean score of %0.4f\"\n",
    "                   % (xgboost_miss_val_times[-1], xgboost_miss_val_scores[-1]))        \n",
    "        \n",
    "        # Imp + XGB's GB\n",
    "        if 6 in bench_mask:\n",
    "            start = timer()\n",
    "            xgboost_impute_scores[experiment_i] = (\n",
    "                cross_val_score(xgboost_impute, X, y, cv=cv).mean())\n",
    "            xgboost_impute_times = timer() - start\n",
    "            print (\"Imp + XGBoost GB completed in %0.2f s\"\n",
    "                   \"with a mean score of %0.4f\"\n",
    "                   % (xgboost_impute_times[experiment_i],\n",
    "                      xgboost_impute_scores[experiment_i]))        \n",
    "            print\n",
    "                                     \n",
    "        # XGB's RF w/MV\n",
    "        if 7 in bench_mask:\n",
    "            start = timer()\n",
    "            xgbrf_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(xgbrf_miss_val, X, y, cv=cv).mean())\n",
    "            xgbrf_miss_val_times[experiment_i] = timer() - start\n",
    "            print (\"XGBoosts RF  w/miss val handled internally completed\"\n",
    "                   \" in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (xgbrf_miss_val_times[experiment_i],\n",
    "                      xgbrf_miss_val_scores[experiment_i]))\n",
    "\n",
    "        # Imp + XGB's RF\n",
    "        if 8 in bench_mask:\n",
    "            start = timer()\n",
    "            xgbrf_impute_scores[experiment_i] = (\n",
    "                cross_val_score(xgbrf_impute, X, y, cv=cv).mean())\n",
    "            xgbrf_impute_times[experiment_i] = timer() - start\n",
    "            print (\"Imp + XGBoosts RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (xgbrf_impute_times[experiment_i],\n",
    "                      xgbrf_impute_scores[experiment_i]))\n",
    "            print\n",
    "            \n",
    "        # RF w/MV and bootstrap set to True\n",
    "        if 9 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_miss_val_btstrp_scores[experiment_i] = (\n",
    "                cross_val_score(rf_miss_val_btstrp, X, y, cv=cv).mean())\n",
    "            rf_miss_val_btstrp_times[experiment_i] = timer() - start\n",
    "            print (\"RF w/MV w/bootstrap completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_miss_val_btstrp_times[experiment_i],\n",
    "                      rf_miss_val_btstrp_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + RF w boostrap set to True\n",
    "        if 10 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_impute_btstrp_scores[experiment_i] = (\n",
    "                cross_val_score(rf_impute_btstrp, X, y, cv=cv).mean())\n",
    "            rf_impute_btstrp_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + RF w/bootstrap completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_impute_btstrp_times[experiment_i],\n",
    "                      rf_impute_btstrp_scores[experiment_i]))\n",
    "\n",
    "        print \"-------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score/Time plot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the plot legend\n",
    "est_labels = [\n",
    "    'RF w/MV with no bootstrap',                               # 0\n",
    "    'IMP + RF with no bootstrap',                              # 1\n",
    "    'Missing max replaced + RF (with btstrp)',                 # 2\n",
    "    'IMP + Dummy',                                             # 3\n",
    "    'IMP + Logit',                                             # 4\n",
    "    'XGB w/MV handled internally',                             # 5\n",
    "    'IMP + XGB',                                               # 6\n",
    "    'XGBs RF w/MV handled internally',                         # 7\n",
    "    'IMP + XGBs RF',                                           # 8\n",
    "    'RF w/MV with bootstrap',                                  # 9\n",
    "    'IMP + RF w/o MV with bootstrap',                          # 10\n",
    "]            \n",
    "\n",
    "# The estimators/techniques for the score plots\n",
    "score_plot_mask =  [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "]\n",
    "\n",
    "# The estimators/techniques for the time plots\n",
    "time_plot_mask =  [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'][:] = [12, 12]\n",
    "plt.rcParams['font.size'] = 12.\n",
    "plt.rcParams['axes.labelsize'] = 'large'\n",
    "\n",
    "# Plot the scores and times\n",
    "index = 0\n",
    "if label_correlation != 0:\n",
    "        print \"Labels correlated with - %s\" % str(labels)\n",
    "\n",
    "# For the score plot\n",
    "plot_colors = ['olive', 'lightpink', 'g', 'b', 'yellow', 'brown', 'm',\n",
    "               'cyan', 'lime', 'r', 'k']\n",
    "\n",
    "for idx, label_correlation in enumerate(label_correlations):\n",
    "    print \"Label correlation - %0.2f\" % label_correlation\n",
    "    print\n",
    "    \n",
    "    title = (\"Benchmark scores and times when label_correlation is %0.2f. n_estimators=%d\"\n",
    "             % (label_correlation, n_estimators))\n",
    "    title += \"\\nDataset - %s. Data shape - %s.\" % (dataset_name, str(data.shape))\n",
    "    print \"Plotting the\", title.lower()\n",
    "    \n",
    "    current_slice = range(index, index + n_missing_fractions[idx])\n",
    "    index += n_missing_fractions[idx]\n",
    "    \n",
    "    all_scores = np.array([\n",
    "        rf_miss_val_scores[current_slice],\n",
    "        rf_impute_scores[current_slice],\n",
    "        rf_max_min_scores[current_slice],\n",
    "        dummy_impute_scores[current_slice],\n",
    "        logit_impute_scores[current_slice],\n",
    "        xgboost_miss_val_scores[current_slice],\n",
    "        xgboost_impute_scores[current_slice],\n",
    "        xgbrf_miss_val_scores[current_slice],\n",
    "        xgbrf_impute_scores[current_slice],\n",
    "        rf_miss_val_btstrp_scores[current_slice],\n",
    "        rf_impute_btstrp_scores[current_slice],\n",
    "        ])\n",
    "\n",
    "    all_times = np.array([\n",
    "        rf_miss_val_times[current_slice],\n",
    "        rf_impute_times[current_slice],\n",
    "        rf_max_min_times[current_slice],\n",
    "        dummy_impute_times[current_slice],\n",
    "        logit_impute_times[current_slice],\n",
    "        xgboost_miss_val_times[current_slice],\n",
    "        xgboost_impute_times[current_slice],\n",
    "        xgbrf_miss_val_times[current_slice],\n",
    "        xgbrf_impute_times[current_slice],\n",
    "        rf_miss_val_btstrp_times[current_slice],\n",
    "        rf_impute_btstrp_times[current_slice],\n",
    "    ])\n",
    "    \n",
    "    #print missing_fractions[idx]\n",
    "    #print current_slice\n",
    "    fig, ax1 = plt.subplots()\n",
    "    # Get the right y axis for time plot\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # A straight line for the baseline score\n",
    "    # The first score is computed with no missing values\n",
    "    l1 = ax1.axhline(all_scores[0][0], label='Baseline score of skl-s RF w/o MV w/o bootstrp',\n",
    "                     color='darkgrey', linewidth=2)\n",
    "    \n",
    "    for i, scores in enumerate(all_scores):\n",
    "        # print i\n",
    "        if i in score_plot_mask:\n",
    "            l2 = ax1.plot(missing_fractions[idx], scores,\n",
    "                          'o-',\n",
    "                          color=plot_colors[i],\n",
    "                          label=\"Scores for %s\" % est_labels[i],\n",
    "                          linewidth=2)\n",
    "\n",
    "    for i, times in enumerate(all_times):\n",
    "        # print i\n",
    "        if i in time_plot_mask:\n",
    "            l3 = ax2.plot(missing_fractions[idx], times,\n",
    "                          '.--',\n",
    "                          color=plot_colors[i],\n",
    "                          linewidth=2,\n",
    "                          alpha=0.4)    \n",
    "\n",
    "    # Compute the axis extremes, to position the legend cleanly\n",
    "    score_decimals = 2\n",
    "    min_score = np.round(np.min(all_scores[score_plot_mask][all_scores[score_plot_mask]!=0]),\n",
    "                         score_decimals) - 0.1**score_decimals\n",
    "    max_score = np.round(np.max(all_scores[score_plot_mask]),\n",
    "                         score_decimals) + 0.1**score_decimals\n",
    "    \n",
    "    score_space_for_legend = (max_score - min_score) / 5.\n",
    "    \n",
    "    min_time = np.min(all_times[time_plot_mask][all_times[time_plot_mask]!=0])\n",
    "    max_time = np.max(all_times[time_plot_mask])\n",
    "    \n",
    "    time_space_for_legend = (max_time - min_time) / 5.\n",
    "    \n",
    "    ax1.set_xlim([missing_fractions[idx][0], missing_fractions[idx][-1]])\n",
    "    ax1.set_ylim([min_score, max_score + score_space_for_legend])\n",
    "    ax1.set_yticks(np.arange(min_score, max_score, 0.1**score_decimals))\n",
    "    ax1.set_ylabel('Mean cross_val_score over 3 iterations of SSS')\n",
    "    ax1.grid(True, alpha=0.6)\n",
    "    \n",
    "    ax2.set_ylabel('Time taken (in seconds) for cross_val_score (For the dashed line plots)')\n",
    "    ax2.set_ylim([min_time, max_time + time_space_for_legend])\n",
    "    \n",
    "    ax1.legend(loc=1)\n",
    "    # ax2.grid(True)\n",
    "    # ax2.legend(loc='best')\n",
    "    \n",
    "    # plt.legend(loc='best')\n",
    "    \n",
    "    ax1.set_xlabel(\"Fraction of samples missing\")    \n",
    "    plt.title(title)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0, 2, 3],\n",
    "              [6, 8, 5],\n",
    "              [2, 3, 4],\n",
    "              [5, 6, 7],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [9, 8, 8],\n",
    "              [10, 0, 1]], dtype=np.float)\n",
    "\n",
    "y = np.array([1, 1, 0, 0, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "mm = np.isnan(X)\n",
    "\n",
    "X, y, mm = drop_values(X, y, missing_mask=mm, missing_fraction=0.1,\n",
    "                       labels=[1], label_correlation=0.75,\n",
    "                       return_missing_mask=True,\n",
    "                       random_state=42)\n",
    "\n",
    "print X, mm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_mask[y!=1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_values(data, target, missing_fraction=0.0,\n",
    "            missing_mask=mm,\n",
    "            return_missing_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rf_with_impute.fit(data, target)\n",
    "\n",
    "#rf_missing_val.estimators_[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pygraphviz as pgv\n",
    "import networkx as nx\n",
    "import pygraphviz\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from StringIO import StringIO\n",
    "from io import BytesIO\n",
    "\n",
    "def get_graph(dtc, n_classes, feat_names=None, size=[7, 7], max_depth=10):\n",
    "    dot_file = StringIO()\n",
    "    image_file = BytesIO()\n",
    "\n",
    "    # Get the dot graph of our decision tree\n",
    "    export_graphviz(dtc, out_file=dot_file, feature_names=feat_names,\n",
    "                    rounded=True, filled=True,\n",
    "                    special_characters=True,\n",
    "                    class_names=map(str, range(1, n_classes+1)),\n",
    "                    max_depth=max_depth)\n",
    "    dot_file.seek(0)\n",
    "\n",
    "    # Convert this dot graph into an image\n",
    "    g = pygraphviz.AGraph(dot_file.read())\n",
    "    g.layout('dot')\n",
    "    # g.draw doesn't work when the image object doesn't have a name (with a proper extension)\n",
    "    image_file.name = \"image.png\"\n",
    "    image_file.seek(0)\n",
    "    g.draw(path=image_file)\n",
    "    image_file.seek(0)\n",
    "\n",
    "    # Plot it\n",
    "    plt.figure().set_size_inches(*size)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.imread(fname=image_file))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:, 0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dtc = rf_with_impute.steps[1][1].estimators_[0]\n",
    "#dtc2= rf_miss_val.estimators_[4]\n",
    "print np.isnan(X).mean(), missing_mask.mean()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, missing_values='NaN')\n",
    "#dtc = rf_miss_val.fit(X, y).estimators_[1]\n",
    "dtc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_graph(dtc, n_classes=len(np.unique(y)),\n",
    "          feat_names=np.arange(X.shape[1]), size=[100, 200], max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_miss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_score = np.load('baseline_score.npy')\n",
    "missing_fraction_range = np.load('missing_fraction_range.npy')\n",
    "scores_missing = np.load('scores_missing.npy')\n",
    "scores_impute = np.load('scores_impute.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.plot(missing_fraction_range, seconds_missing, '.--', color='r', label='RF MV enabled')\n",
    "plt.plot(missing_fraction_range, seconds_impute, '.--', color='b', label='RF+imputer')\n",
    "plt.axhline(35, label='RF w/No missing', color='k')\n",
    "#for sample_pt in missing_fraction_range:\n",
    "#    plt.axvline(sample_pt, linestyle='--', color='g')\n",
    "plt.xlabel('Missing fraction')\n",
    "plt.ylabel('Time taken for cross_val_score using 3 iterations of StratifiedShuffleSplit in seconds')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "adult = fetch_mldata('yeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_feats = np.load('cat_feats.npy').tolist()\n",
    "feat_names = np.load('feat_names.npy').tolist()\n",
    "data = np.load('data.npy')\n",
    "target = np.load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging missing value support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toy data which will send all the missing values to the right at the root node\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = np.array(\n",
    "        [[np.nan],\n",
    "         [np.nan],\n",
    "         [np.nan],\n",
    "         [np.nan],\n",
    "         [0],\n",
    "         [1],\n",
    "         [2],\n",
    "         [3],\n",
    "         [12],\n",
    "         [13],\n",
    "         [10],\n",
    "         [11],\n",
    "         [12],\n",
    "         [13],\n",
    "         [14]])\n",
    "\n",
    "y = np.array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_graph(DecisionTreeClassifier(missing_values='NaN').fit(X, y),\n",
    "          n_classes=3, size=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# pylint: disable=too-many-arguments, too-many-locals, invalid-name, fixme\n",
    "\"\"\"Scikit-Learn Wrapper interface for XGBoost.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "from xgboost.core import Booster, DMatrix, XGBoostError\n",
    "from xgboost.training import train\n",
    "\n",
    "from xgboost.compat import (SKLEARN_INSTALLED, XGBModelBase,\n",
    "                            XGBClassifierBase, XGBRegressorBase, LabelEncoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbrf = XGBRFClassifier(n_estimators=n_estimators,\n",
    "                        nthread=n_jobs,\n",
    "                        max_depth=100,\n",
    "                        missing=np.nan,\n",
    "                        objective='multiclass:logistic',\n",
    "                        subsample=0.6,\n",
    "                        seed=random_state,\n",
    "                        base_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(xgbrf, data, target, cv=cv, fit_params={'eval_metric': 'auc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_miss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
