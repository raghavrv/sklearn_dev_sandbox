{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark for RF w/Missing Value support\n",
    "\n",
    "#### Sys stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Linux-3.12.18-enst.1-x86_64-with-debian-7.9\n",
      "At host \"tsilinuxd98\" with 8 cores. Current Dir - /cal/homes/vrajagopalan/raghav/miss_val_bench\n",
      "\n",
      "sklearn 0.18.dev0 in branch \"missing_values_rf\", (c84f089-yohoooooooo it works B) [ci skip])\n",
      "@ ['/tsi/doctorants/raghav/anaconda/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn']\n",
      "\n",
      "np v1.10.4 - scipy v0.17.0 \n",
      "IPython v4.0.3 - Python 2.7.11 :: Anaconda 2.5.0 (64-bit)\n",
      "@ /tsi/doctorants/raghav/anaconda/anaconda3/envs/python2/bin/python\n"
     ]
    }
   ],
   "source": [
    "# To keep track of the machine this script is run in\n",
    "import IPython; import sklearn, numpy as np, scipy; from ast import literal_eval\n",
    "import platform;\n",
    "\n",
    "CURR_IPYTHON_VERSION = IPython.__version__\n",
    "PYTHON_INPT = literal_eval(IPython.sys_info())['sys_executable']\n",
    "SKVERSION = sklearn.__version__; SCVERSION = scipy.__version__; NPVERSION = np.__version__\n",
    "print \"Running on %s\" % platform.platform()\n",
    "!echo -e \"At host \\\"$(hostname)\\\" with $(nproc) cores. Current Dir - $(pwd)\\n\"\n",
    "!echo -n \"sklearn $SKVERSION \"\n",
    "!echo -n \"in branch \\\"\"\n",
    "!echo -n \"$(git --git-dir \"$SCIKIT_LEARN_PATH\"/.git rev-parse --abbrev-ref HEAD)\\\", \"\n",
    "!echo \"($(git --git-dir \"$SCIKIT_LEARN_PATH\"/.git log --pretty=format:'%h-%s' -n 1))\"\n",
    "print \"@ %s\\n\" % str(sklearn.__path__)\n",
    "!echo -e -n \"np v$NPVERSION - scipy v$SCVERSION \\nIPython v$CURR_IPYTHON_VERSION - \"\n",
    "!echo -n \"$($PYTHON_INPT --version)\"\n",
    "!echo \"@ $PYTHON_INPT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from get_graph import get_graph\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from xgbrf import XGBRFClassifier\n",
    "from value_dropper import drop_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOME PARAMETERS\n",
    "\n",
    "plt.rcParams['figure.figsize'][:] = [15, 15]\n",
    "plt.rcParams['font.size'] = 12.\n",
    "plt.rcParams['axes.labelsize'] = 'large'\n",
    "\n",
    "\n",
    "# Use all the cores\n",
    "n_jobs = -1\n",
    "n_estimators = 50\n",
    "imputation_strategy = 'mean'\n",
    "bootstrap = False\n",
    "criterion = 'gini'\n",
    "missing_values = 'NaN'\n",
    "random_state = 42\n",
    "max_depth = 20\n",
    "\n",
    "# To compute max_features, we need the shape of data before\n",
    "# max_features = int(round(sqrt(data.shape[1])))\n",
    "# max_feature_fraction = float(max_features) / data.shape[1]\n",
    "max_feature_fraction = 0.8\n",
    "\n",
    "# Use 3 iterations of SSS\n",
    "cv = StratifiedShuffleSplit(n_iter=3, test_size=0.1,\n",
    "                            random_state=42)\n",
    "\n",
    "\n",
    "# THE ESTIMATORS\n",
    "# 0. RF w/MV\n",
    "rf_miss_val = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                     criterion=criterion,\n",
    "                                     max_features=max_feature_fraction,\n",
    "                                     max_depth=max_depth,\n",
    "                                     bootstrap=bootstrap,\n",
    "                                     missing_values=missing_values,\n",
    "                                     n_jobs=n_jobs,\n",
    "                                     random_state=random_state)\n",
    "\n",
    "# 1. Imputation ---> RF\n",
    "rf_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                      missing_values=missing_values)), \n",
    "                      ('rf', RandomForestClassifier(\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 criterion=criterion,\n",
    "                                 max_features=max_feature_fraction,\n",
    "                                 max_depth=max_depth,\n",
    "                                 bootstrap=bootstrap,\n",
    "                                 # Don't allow missing, we've imputed them\n",
    "                                 missing_values=None,  \n",
    "                                 n_jobs=n_jobs,\n",
    "                                 random_state=random_state))])\n",
    "\n",
    "# 2. estimator to bench {Missing Data replaced with a MAX val + RF}\n",
    "rf_max_min = RandomForestClassifier(\n",
    "                 n_estimators=n_estimators,\n",
    "                 criterion=criterion,\n",
    "                 max_features=max_feature_fraction,\n",
    "                 max_depth=max_depth,\n",
    "                 bootstrap=True,\n",
    "                 missing_values=None,\n",
    "                 n_jobs=n_jobs,\n",
    "                 random_state=42)\n",
    "\n",
    "# 3. Imputation ---> DummyClassifier\n",
    "dummy_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('dum', DummyClassifier())])\n",
    "\n",
    "# 4. Imputation ---> LogisticRegressionCV\n",
    "logit_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('log', LogisticRegressionCV(\n",
    "                                     n_jobs=n_jobs,\n",
    "                                     random_state=random_state))])\n",
    "\n",
    "# 5. Imputation --> XGBoost's Gradient Boosting Clf\n",
    "xgboost_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                           missing_values=missing_values)), \n",
    "                           ('xgb', XGBClassifier(\n",
    "                                       # Don't allow missing, we've imputed them\n",
    "                                       n_estimators=n_estimators,\n",
    "                                       nthread=n_jobs,\n",
    "                                       seed=random_state))])\n",
    "\n",
    "# 6. XGBoost's Gradient Boosting Clf w/missing values handled inherently\n",
    "xgboost_miss_val = XGBClassifier(n_estimators=n_estimators,\n",
    "                                 missing=np.nan,  # XGBoost doesn't accept \"NaN\"\n",
    "                                 nthread=n_jobs,\n",
    "                                 seed=random_state)\n",
    "\n",
    "# 7. Imputation --> XGBoost's RF (using num_parallel_tree)\n",
    "xgbrf_impute = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                         missing_values=missing_values)), \n",
    "                         ('xgb', XGBRFClassifier(\n",
    "                                     n_estimators=n_estimators,\n",
    "                                     # Fraction of features to take for each tree\n",
    "                                     # Take sqrt(n_features) / n_features\n",
    "                                     colsample_bytree=max_feature_fraction,\n",
    "                                     max_depth=max_depth,\n",
    "                                     # No Bootstrapping, choose all samples exactly once\n",
    "                                     num_boost_round=1,\n",
    "                                     subsample=1,  \n",
    "                                     nthread=n_jobs,\n",
    "                                     seed=random_state))])\n",
    "\n",
    "# 8. XGBoost's RF (using num_parallel_tree) w/missing values handled inherently\n",
    "xgbrf_miss_val = XGBRFClassifier(\n",
    "                       n_estimators=n_estimators,\n",
    "                       # Fraction of features to take for each tree\n",
    "                       # Take sqrt(n_features) / n_features\n",
    "                       colsample_bytree=max_feature_fraction,\n",
    "                       max_depth=max_depth,\n",
    "                       # No Bootstrapping, choose all samples exactly once\n",
    "                       missing=np.nan,\n",
    "                       num_boost_round=1,\n",
    "                       subsample=1,\n",
    "                       nthread=n_jobs,\n",
    "                       seed=random_state)\n",
    "\n",
    "# 9. RF w/MV w/bootstrap\n",
    "rf_miss_val_btstrp = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                            bootstrap=True,\n",
    "                                            missing_values=missing_values,\n",
    "                                            max_features=max_feature_fraction,\n",
    "                                            max_depth=max_depth,\n",
    "                                            n_jobs=n_jobs,\n",
    "                                            random_state=random_state)\n",
    "\n",
    "# 10. IMP + RF w/o MV w/bootstrap\n",
    "rf_impute_btstrp = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                             missing_values=missing_values)), \n",
    "                             ('rf', RandomForestClassifier(\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        bootstrap=True,\n",
    "                                        max_features=max_feature_fraction,\n",
    "                                        max_depth=max_depth,\n",
    "                                        # Don't allow missing, we've imputed them\n",
    "                                        missing_values=None,  \n",
    "                                        n_jobs=n_jobs,\n",
    "                                        random_state=random_state))])\n",
    "\n",
    "# 11. IMP + RF w/o MV w/bootstrap\n",
    "\n",
    "rf_impute_btstrp = Pipeline([('imp', Imputer(strategy=imputation_strategy,\n",
    "                                             missing_values=missing_values)), \n",
    "                             ('rf', RandomForestClassifier(\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        bootstrap=True,\n",
    "                                        max_features=max_feature_fraction,\n",
    "                                        max_depth=max_depth,\n",
    "                                        # Don't allow missing, we've imputed them\n",
    "                                        missing_values=None,  \n",
    "                                        n_jobs=n_jobs,\n",
    "                                        random_state=random_state))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 % of values missing\n",
      "The shape of the entire dataset - (581012, 54); Target - (581012,)\n",
      "The shape of the subsampled dataset - (14526, 54)\n",
      "\n",
      "The maximum data value : 50098084.00 and minimum value : 23716.00\n",
      "\n",
      "Labels -\t[1 2 3 4 5 6 7]\n",
      "Label counts -\t[5285 7108  873   64  236  439  521]\n",
      "\n",
      "For MNAR case, the labels to correlate are - [1]\n",
      "\n",
      "The histogram of the label counts\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAE8CAYAAABTrHNpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5c268f190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset_names = [\"covtype\", \"iris\", \"make_classification\"]\n",
    "\n",
    "dataset_name = all_dataset_names[0]\n",
    "\n",
    "if dataset_name == \"covtype\":\n",
    "    dataset = fetch_covtype()\n",
    "    data, target = dataset.data, dataset.target\n",
    "    subsample_dataset = True\n",
    "    make_binary = False\n",
    "    subsample_interval = 40\n",
    "\n",
    "elif dataset_name == \"iris\":\n",
    "    dataset = load_iris()\n",
    "    data, target = dataset.data, dataset.target\n",
    "    subsample_dataset = False\n",
    "    make_binary = False\n",
    "\n",
    "elif dataset_name == \"make_classification\":\n",
    "    data, target = make_classification(n_samples=10000, n_features=8,\n",
    "                                       n_informative=6, n_redundant=2,\n",
    "                                       n_classes=8,\n",
    "                                       n_clusters_per_class=2,\n",
    "                                       random_state=42)\n",
    "    subsample_dataset = False\n",
    "    make_binary = False\n",
    "\n",
    "# densify\n",
    "if scipy.sparse.issparse(data):\n",
    "    print \"Data is sparse! Attempting densification\"\n",
    "    data = data.toarray()\n",
    "\n",
    "# Initially we have no missing\n",
    "print \"%0.2f %% of values missing\" % (np.mean(np.isnan(target))*100)\n",
    "\n",
    "print \"The shape of the entire dataset - %s; Target - %s\" % (str(data.shape), str(target.shape))\n",
    "if subsample_dataset:\n",
    "    #Subsample the data\n",
    "    data, target = data[::subsample_interval], target[::subsample_interval]\n",
    "    print \"The shape of the subsampled dataset - %s\" % str(data.shape)\n",
    "    print\n",
    "\n",
    "if make_binary:\n",
    "    mask = target <= 2\n",
    "    data, target = data[mask], target[mask]\n",
    "    print \"The shape of the binary dataset - %s\" % str(data.shape)\n",
    "    print\n",
    "\n",
    "# Set the data_max and data_min vars\n",
    "data_max = data.max() ** 2\n",
    "data_min = data.min() ** 2\n",
    "\n",
    "\n",
    "print \"The maximum data value : %0.2f and minimum value : %0.2f\" % (data_max, data_min)\n",
    "print\n",
    "\n",
    "labels = np.unique(target)\n",
    "print \"Labels -\\t\", labels\n",
    "label_counts = np.bincount(target)[-len(labels):]\n",
    "print \"Label counts -\\t\", label_counts\n",
    "print\n",
    "\n",
    "labels_to_correlate_for_mnar = [1]\n",
    "\n",
    "print \"For MNAR case, the labels to correlate are - %s\" % labels_to_correlate_for_mnar\n",
    "print\n",
    "\n",
    "print \"The histogram of the label counts\"\n",
    "\n",
    "old_fig_size = plt.rcParams['figure.figsize'][:]\n",
    "plt.rcParams['figure.figsize'][:] = [5, 5]\n",
    "plt.bar(labels+0, label_counts, color='k', align='center')\n",
    "plt.xlim([np.min(labels)-0.5, np.max(labels)+0.5])\n",
    "plt.rcParams['figure.figsize'][:] = old_fig_size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selectively Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the plot legend\n",
    "est_labels = [\n",
    "    'RF w/MV',                                # 0\n",
    "    'IMP + RF',                               # 1\n",
    "    'Missing max replaced + RF',              # 2\n",
    "    'IMP + Dummy',                            # 3\n",
    "    'IMP + Logit',                            # 4\n",
    "    'XGB w/MV handled internally',            # 5\n",
    "    'IMP + XGB',                              # 6\n",
    "    'XGBs RF w/MV handled internally',        # 7\n",
    "    'IMP + XGBs RF',                          # 8\n",
    "    'RF w/MV with bootstrap True',            # 9\n",
    "    'IMP + RF w/o MV with bootstrap True',    # 10\n",
    "]  \n",
    "\n",
    "# The estimators/techniques to run for benchmarking\n",
    "bench_mask = [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "#     7,\n",
    "#     8,\n",
    "    9,\n",
    "    10,\n",
    "]\n",
    "\n",
    "n_experiments_per_plot = 10\n",
    "n_correlation_levels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some baseline scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (RF) is %0.8f'\n",
    "#       % cross_val_score(rf_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (xgboost) is %0.8f'\n",
    "#       % cross_val_score(xgboost_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ('The baseline score without missing (xgboost) is %0.8f'\n",
    "#       % cross_val_score(xgbrf_miss_val, data, target, cv=cv).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bench mask is [9, 10]\n",
      "0.363830373124\n",
      "The bench_mask [9, 10]\n",
      "Labels correlated with - None\n",
      "Label correlation - 0.80\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 0/0\n",
      "Missing fraction - (Expected - 0.0000, Actual - 0.0000)\n",
      "Fraction of samples missing when label == 1 - 0.0000\n",
      "Fraction of samples missing when label != 1 - 0.0000\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 3.24 s with a mean score of 0.8181\n",
      "IMP + RF w/bootstrap completed in 3.17 s with a mean score of 0.8181\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 55779/13945\n",
      "Missing fraction - (Expected - 0.0889, Actual - 0.0889)\n",
      "Fraction of samples missing when label == 1 - 0.1954\n",
      "Fraction of samples missing when label != 1 - 0.0279\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 4.45 s with a mean score of 0.9053\n",
      "IMP + RF w/bootstrap completed in 3.75 s with a mean score of 0.8910\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 55780/13945\n",
      "Missing fraction - (Expected - 0.1778, Actual - 0.1778)\n",
      "Fraction of samples missing when label == 1 - 0.3909\n",
      "Fraction of samples missing when label != 1 - 0.0559\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 4.09 s with a mean score of 0.9282\n",
      "IMP + RF w/bootstrap completed in 3.57 s with a mean score of 0.9174\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 55780/13945\n",
      "Missing fraction - (Expected - 0.2667, Actual - 0.2667)\n",
      "Fraction of samples missing when label == 1 - 0.5864\n",
      "Fraction of samples missing when label != 1 - 0.0838\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 3.81 s with a mean score of 0.9321\n",
      "IMP + RF w/bootstrap completed in 3.62 s with a mean score of 0.9337\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 55780/13945\n",
      "Missing fraction - (Expected - 0.3556, Actual - 0.3556)\n",
      "Fraction of samples missing when label == 1 - 0.7818\n",
      "Fraction of samples missing when label != 1 - 0.1118\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 3.66 s with a mean score of 0.9321\n",
      "IMP + RF w/bootstrap completed in 3.30 s with a mean score of 0.9319\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "No of (additional) correlated/uncorrelated missing values - 55780/13945\n",
      "Missing fraction - (Expected - 0.4444, Actual - 0.4444)\n",
      "Fraction of samples missing when label == 1 - 0.9773\n",
      "Fraction of samples missing when label != 1 - 0.1397\n",
      "-------------------------------------------------------\n",
      "RF w/MV w/bootstrap completed in 3.49 s with a mean score of 0.9314\n",
      "IMP + RF w/bootstrap completed in 3.27 s with a mean score of 0.9344\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2fb071de9587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mreturn_missing_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mreturn_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             )\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cal/homes/vrajagopalan/raghav/miss_val_bench/value_dropper.pyc\u001b[0m in \u001b[0;36mdrop_values\u001b[1;34m(X, y, missing_mask, missing_values, missing_fraction, label_correlation, n_labels, labels, missing_mask_only, return_labels, return_missing_mask, copy, random_state)\u001b[0m\n\u001b[0;32m    168\u001b[0m         corr_chosen = rng.choice(n_corr_available,\n\u001b[0;32m    169\u001b[0m                                  \u001b[0mn_corr_chosen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                                  replace=False)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mn_uncorr_chosen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_more_missing\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_corr_chosen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:12517)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "print 'The bench mask is %s' % bench_mask\n",
    "\n",
    "missing_mask = np.zeros(data.shape, dtype=bool)\n",
    "labels = None\n",
    "\n",
    "label_1_fraction = np.mean(target==labels_to_correlate_for_mnar[0])\n",
    "print label_1_fraction\n",
    "\n",
    "label_correlations = (0.8, 1)# np.linspace(0, 1, n_correlation_levels)\n",
    "missing_fractions = ([np.linspace(0, 0.80, n_experiments_per_plot),] +\n",
    "                     # Label 1 accounts of only around 35% of the samples\n",
    "                     [np.linspace(0,\n",
    "                                  0.9 * label_1_fraction,\n",
    "                                  n_experiments_per_plot),]*(len(label_correlations)-1))\n",
    "\n",
    "rng = np.random.RandomState(random_state)\n",
    "                        \n",
    "n_samples, n_features = data.shape\n",
    "n_missing_fractions = list(map(len, missing_fractions))\n",
    "\n",
    "n_experiments = len(label_correlations) * sum(n_missing_fractions)\n",
    "\n",
    "# Intialize the scores and times with zeros\n",
    "rf_miss_val_scores = np.zeros(n_experiments)\n",
    "rf_impute_scores = np.zeros(n_experiments)\n",
    "rf_max_min_scores = np.zeros(n_experiments)\n",
    "dummy_impute_scores = np.zeros(n_experiments)\n",
    "logit_impute_scores = np.zeros(n_experiments)\n",
    "xgboost_impute_scores = np.zeros(n_experiments)\n",
    "xgboost_miss_val_scores = np.zeros(n_experiments)\n",
    "xgbrf_miss_val_scores = np.zeros(n_experiments)\n",
    "xgbrf_impute_scores = np.zeros(n_experiments)\n",
    "rf_miss_val_btstrp_scores = np.zeros(n_experiments)\n",
    "rf_impute_btstrp_scores = np.zeros(n_experiments)\n",
    "\n",
    "rf_miss_val_times = np.zeros(n_experiments)\n",
    "rf_impute_times = np.zeros(n_experiments)\n",
    "rf_max_min_times = np.zeros(n_experiments)\n",
    "dummy_impute_times = np.zeros(n_experiments)\n",
    "logit_impute_times = np.zeros(n_experiments)\n",
    "xgboost_impute_times = np.zeros(n_experiments)\n",
    "xgboost_miss_val_times = np.zeros(n_experiments)\n",
    "xgbrf_miss_val_times = np.zeros(n_experiments)\n",
    "xgbrf_impute_times = np.zeros(n_experiments)\n",
    "rf_miss_val_btstrp_times = np.zeros(n_experiments)\n",
    "rf_impute_btstrp_times = np.zeros(n_experiments)\n",
    "\n",
    "experiment_i = -1\n",
    "print \"The bench_mask\", bench_mask\n",
    "for i, label_correlation in enumerate(label_correlations):\n",
    "    print \"Labels correlated with - %s\" % str(labels)\n",
    "    print \"Label correlation - %0.2f\" % label_correlation\n",
    "    print\n",
    "    \n",
    "    X, y = data.copy(), target.copy()\n",
    "    missing_mask = np.zeros(X.shape, dtype=bool)\n",
    "    labels = labels_to_correlate_for_mnar\n",
    "        \n",
    "    for j, missing_fraction in enumerate(missing_fractions[i]):\n",
    "        print\n",
    "        print \"-------------------------------------------------------\"\n",
    "        \n",
    "        \"\"\"\n",
    "        # Old way of generating missing data --------------------------\n",
    "        rv = rng.randn(*X.shape)\n",
    "        rv = rng.randn(*X.shape)\n",
    "        thresh = np.sort(rv.ravel())[int(missing_fraction * n_samples * n_features)]\n",
    "        missing_mask += rv < thresh\n",
    "        if label_correlation == 1:  # MNAR\n",
    "            missing_mask[y!=labels[0]] = False  # Features should go missing only for y=1\n",
    "        X[missing_mask] = np.nan\n",
    "        # -------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate the missing values using the `drop_values` function\n",
    "        X, y, missing_mask, label = drop_values(\n",
    "            X, y,\n",
    "            missing_mask=missing_mask,\n",
    "            missing_fraction=missing_fraction,\n",
    "            # The MCAR-ness should not change\n",
    "            label_correlation=label_correlation,\n",
    "            # Persist the correlation with the same label\n",
    "            labels=labels,\n",
    "            return_missing_mask=True,\n",
    "            return_labels=True,\n",
    "            random_state=random_state,\n",
    "            )\n",
    "        \n",
    "        print (\"Missing fraction - (Expected - %0.4f, Actual - %0.4f)\"\n",
    "               % (missing_fraction, missing_mask.mean()))\n",
    "        print (\"Fraction of samples missing when label == %d - %0.4f\"\n",
    "               % (labels[0], missing_mask[y==labels[0]].mean()))\n",
    "        print (\"Fraction of samples missing when label != %d - %0.4f\"\n",
    "               % (labels[0], missing_mask[y!=labels[0]].mean()))\n",
    "        print \"-------------------------------------------------------\"\n",
    "        \n",
    "        experiment_i += 1\n",
    "        \n",
    "        # RF w/MV\n",
    "        if 0 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(rf_miss_val, X, y, cv=cv).mean())\n",
    "            rf_miss_val_times[experiment_i] = timer() - start\n",
    "            print (\"RF w/MV completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_miss_val_times[experiment_i],\n",
    "                      rf_miss_val_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + RF\n",
    "        if 1 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_impute_scores[experiment_i] = (\n",
    "                cross_val_score(rf_impute, X, y, cv=cv).mean())\n",
    "            rf_impute_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_impute_times[experiment_i],\n",
    "                      rf_impute_scores[experiment_i]))\n",
    "            print\n",
    "        \n",
    "        # X replaced + RF\n",
    "        if 2 in bench_mask:\n",
    "            # Replace X's nan with data_max/data_min\n",
    "            X[missing_mask] = data_max\n",
    "            start = timer()\n",
    "            rf_max_min_scores[experiment_i] = (\n",
    "                cross_val_score(rf_max_min, X, y, cv=cv).mean())\n",
    "            rf_max_min_times[experiment_i] = timer() - start\n",
    "            # Revert the change\n",
    "            X[missing_mask] = np.nan\n",
    "            print (\"Missing replaced + RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_max_min_times[experiment_i],\n",
    "                      rf_max_min_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + Dummy\n",
    "        if 3 in bench_mask:\n",
    "            start = timer()\n",
    "            dummy_impute_scores[experiment_i] = (\n",
    "                cross_val_score(dummy_impute, X, y, cv=cv).mean())\n",
    "            dummy_impute_times = timer() - start\n",
    "            print (\"IMP + Dummy completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (dummy_impute_times[experiment_i],\n",
    "                      dummy_impute_scores[experiment_i]))\n",
    "            print\n",
    "\n",
    "\n",
    "        # IMP + Logistic Regression\n",
    "        if 4 in bench_mask:\n",
    "            start = timer()\n",
    "            logit_impute_scores[experiment_i] = (\n",
    "                cross_val_score(logit_impute, X, y, cv=cv).mean())\n",
    "            logit_impute_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + Logit completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (logit_impute_times[experiment_i],\n",
    "                      logit_impute_scores[experiment_i]))\n",
    "            print\n",
    "\n",
    "        # XGB's GB w/MV\n",
    "        if 5 in bench_mask:\n",
    "            start = timer()\n",
    "            xgboost_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(xgboost_miss_val, X, y, cv=cv).mean())\n",
    "            xgboost_miss_val_times = timer() - start\n",
    "            print (\"XGBoost w/miss val handled internally completed in %0.2f s \"\n",
    "                   \"with a mean score of %0.4f\"\n",
    "                   % (xgboost_miss_val_times[-1], xgboost_miss_val_scores[-1]))        \n",
    "        \n",
    "        # Imp + XGB's GB\n",
    "        if 6 in bench_mask:\n",
    "            start = timer()\n",
    "            xgboost_impute_scores[experiment_i] = (\n",
    "                cross_val_score(xgboost_impute, X, y, cv=cv).mean())\n",
    "            xgboost_impute_times = timer() - start\n",
    "            print (\"Imp + XGBoost GB completed in %0.2f s\"\n",
    "                   \"with a mean score of %0.4f\"\n",
    "                   % (xgboost_impute_times[experiment_i],\n",
    "                      xgboost_impute_scores[experiment_i]))        \n",
    "            print\n",
    "                                     \n",
    "        # XGB's RF w/MV\n",
    "        if 7 in bench_mask:\n",
    "            start = timer()\n",
    "            xgbrf_miss_val_scores[experiment_i] = (\n",
    "                cross_val_score(xgbrf_miss_val, X, y, cv=cv).mean())\n",
    "            xgbrf_miss_val_times[experiment_i] = timer() - start\n",
    "            print (\"XGBoosts RF  w/miss val handled internally completed\"\n",
    "                   \" in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (xgbrf_miss_val_times[experiment_i],\n",
    "                      xgbrf_miss_val_scores[experiment_i]))\n",
    "\n",
    "        # Imp + XGB's RF\n",
    "        if 8 in bench_mask:\n",
    "            start = timer()\n",
    "            xgbrf_impute_scores[experiment_i] = (\n",
    "                cross_val_score(xgbrf_impute, X, y, cv=cv).mean())\n",
    "            xgbrf_impute_times[experiment_i] = timer() - start\n",
    "            print (\"Imp + XGBoosts RF completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (xgbrf_impute_times[experiment_i],\n",
    "                      xgbrf_impute_scores[experiment_i]))\n",
    "            print\n",
    "            \n",
    "        # RF w/MV and bootstrap set to True\n",
    "        if 9 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_miss_val_btstrp_scores[experiment_i] = (\n",
    "                cross_val_score(rf_miss_val_btstrp, X, y, cv=cv).mean())\n",
    "            rf_miss_val_btstrp_times[experiment_i] = timer() - start\n",
    "            print (\"RF w/MV w/bootstrap completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_miss_val_btstrp_times[experiment_i],\n",
    "                      rf_miss_val_btstrp_scores[experiment_i]))\n",
    "        \n",
    "        # IMP + RF w boostrap set to True\n",
    "        if 10 in bench_mask:\n",
    "            start = timer()\n",
    "            rf_impute_btstrp_scores[experiment_i] = (\n",
    "                cross_val_score(rf_impute_btstrp, X, y, cv=cv).mean())\n",
    "            rf_impute_btstrp_times[experiment_i] = timer() - start\n",
    "            print (\"IMP + RF w/bootstrap completed in %0.2f s with a mean score of %0.4f\"\n",
    "                   % (rf_impute_btstrp_times[experiment_i],\n",
    "                      rf_impute_btstrp_scores[experiment_i]))\n",
    "\n",
    "        print \"-------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score/Time plot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the plot legend\n",
    "est_labels = [\n",
    "    'RF w/MV with no bootstrap',                               # 0\n",
    "    'IMP + RF with no bootstrap',                              # 1\n",
    "    'Missing max replaced + RF (with btstrp)',                 # 2\n",
    "    'IMP + Dummy',                                             # 3\n",
    "    'IMP + Logit',                                             # 4\n",
    "    'XGB w/MV handled internally',                             # 5\n",
    "    'IMP + XGB',                                               # 6\n",
    "    'XGBs RF w/MV handled internally',                         # 7\n",
    "    'IMP + XGBs RF',                                           # 8\n",
    "    'RF w/MV with bootstrap',                                  # 9\n",
    "    'IMP + RF w/o MV with bootstrap',                          # 10\n",
    "]            \n",
    "\n",
    "# The estimators/techniques for the score plots\n",
    "score_plot_mask =  [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "#     7,\n",
    "#     8,\n",
    "    9,\n",
    "    10,\n",
    "]\n",
    "\n",
    "# The estimators/techniques for the time plots\n",
    "time_plot_mask =  [\n",
    "#     0,\n",
    "#     1,\n",
    "#     2,\n",
    "#     3,\n",
    "#     4,\n",
    "#     5,\n",
    "#     6,\n",
    "#     7,\n",
    "#     8,\n",
    "    9,\n",
    "    10,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the scores and times\n",
    "index = 0\n",
    "if label_correlation != 0:\n",
    "        print \"Labels correlated with - %s\" % str(labels)\n",
    "\n",
    "# For the score plot\n",
    "plot_colors = ['olive', 'lightpink', 'g', 'b', 'yellow', 'brown', 'm',\n",
    "               'cyan', 'lime', 'r', 'k']\n",
    "\n",
    "for idx, label_correlation in enumerate(label_correlations):\n",
    "    print \"Label correlation - %0.2f\" % label_correlation\n",
    "    print\n",
    "    \n",
    "    title = (\"Benchmark scores and times when label_correlation is %0.2f. n_estimators=%d\"\n",
    "             % (label_correlation, n_estimators))\n",
    "    title += \"\\nDataset - %s. Data shape - %s.\" % (dataset_name, str(data.shape))\n",
    "    print \"Plotting the\", title.lower()\n",
    "    \n",
    "    current_slice = range(index, index + n_missing_fractions[idx])\n",
    "    index += n_missing_fractions[idx]\n",
    "    \n",
    "    all_scores = np.array([\n",
    "        rf_miss_val_scores[current_slice],\n",
    "        rf_impute_scores[current_slice],\n",
    "        rf_max_min_scores[current_slice],\n",
    "        dummy_impute_scores[current_slice],\n",
    "        logit_impute_scores[current_slice],\n",
    "        xgboost_miss_val_scores[current_slice],\n",
    "        xgboost_impute_scores[current_slice],\n",
    "        xgbrf_miss_val_scores[current_slice],\n",
    "        xgbrf_impute_scores[current_slice],\n",
    "        rf_miss_val_btstrp_scores[current_slice],\n",
    "        rf_impute_btstrp_scores[current_slice],\n",
    "        ])\n",
    "\n",
    "    all_times = np.array([\n",
    "        rf_miss_val_times[current_slice],\n",
    "        rf_impute_times[current_slice],\n",
    "        rf_max_min_times[current_slice],\n",
    "        dummy_impute_times[current_slice],\n",
    "        logit_impute_times[current_slice],\n",
    "        xgboost_miss_val_times[current_slice],\n",
    "        xgboost_impute_times[current_slice],\n",
    "        xgbrf_miss_val_times[current_slice],\n",
    "        xgbrf_impute_times[current_slice],\n",
    "        rf_miss_val_btstrp_times[current_slice],\n",
    "        rf_impute_btstrp_times[current_slice],\n",
    "    ])\n",
    "    \n",
    "    #print missing_fractions[idx]\n",
    "    #print current_slice\n",
    "    fig, ax1 = plt.subplots()\n",
    "    # Get the right y axis for time plot\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # A straight line for the baseline score\n",
    "    # The first score is computed with no missing values\n",
    "    l1 = ax1.axhline(all_scores[0][0], label='Baseline score of skl-s RF w/o MV w/o bootstrp',\n",
    "                     color='darkgrey', linewidth=2)\n",
    "    \n",
    "    for i, scores in enumerate(all_scores):\n",
    "        # print i\n",
    "        if i in score_plot_mask:\n",
    "            l2 = ax1.plot(missing_fractions[idx], scores,\n",
    "                          'o-',\n",
    "                          color=plot_colors[i],\n",
    "                          label=\"Scores for %s\" % est_labels[i],\n",
    "                          linewidth=2)\n",
    "\n",
    "    for i, times in enumerate(all_times):\n",
    "        # print i\n",
    "        if i in time_plot_mask:\n",
    "            l3 = ax2.plot(missing_fractions[idx], times,\n",
    "                          '.--',\n",
    "                          color=plot_colors[i],\n",
    "                          linewidth=2,\n",
    "                          alpha=0.4)    \n",
    "\n",
    "    # Compute the axis extremes, to position the legend cleanly\n",
    "    score_decimals = 2\n",
    "    min_score = np.round(np.min(all_scores[score_plot_mask][all_scores[score_plot_mask]!=0]),\n",
    "                         score_decimals) - 0.1**score_decimals\n",
    "    max_score = np.round(np.max(all_scores[score_plot_mask]),\n",
    "                         score_decimals)+0.1**score_decimals\n",
    "    \n",
    "    score_space_for_legend = (max_score - min_score) / 5.\n",
    "    \n",
    "    min_time = np.min(all_times[time_plot_mask][all_times[time_plot_mask]!=0])\n",
    "    max_time = np.max(all_times[time_plot_mask])\n",
    "    \n",
    "    time_space_for_legend = (max_time - min_time) / 5.\n",
    "    \n",
    "    ax1.set_xlim([missing_fractions[idx][0], missing_fractions[idx][-1]])\n",
    "    ax1.set_ylim([min_score, max_score + score_space_for_legend])\n",
    "    ax1.set_yticks(np.arange(min_score, max_score, 0.1**score_decimals))\n",
    "    ax1.set_ylabel('Mean cross_val_score over 3 iterations of SSS')\n",
    "    ax1.grid(True, alpha=0.6)\n",
    "    \n",
    "    ax2.set_ylabel('Time taken (in seconds) for cross_val_score (For the dashed line plots)')\n",
    "    ax2.set_ylim([min_time, max_time + time_space_for_legend])\n",
    "    \n",
    "    ax1.legend(loc=1)\n",
    "    # ax2.grid(True)\n",
    "    # ax2.legend(loc='best')\n",
    "    \n",
    "    # plt.legend(loc='best')\n",
    "    \n",
    "    ax1.set_xlabel(\"Fraction of samples missing\")    \n",
    "    plt.title(title)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0, 2, 3],\n",
    "              [6, 8, 5],\n",
    "              [2, 3, 4],\n",
    "              [5, 6, 7],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [8, 8, 8],\n",
    "              [9, 8, 8],\n",
    "              [10, 0, 1]], dtype=np.float)\n",
    "\n",
    "y = np.array([1, 1, 0, 0, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "mm = np.isnan(X)\n",
    "\n",
    "X, y, mm = drop_values(X, y, missing_mask=mm, missing_fraction=0.1,\n",
    "                       labels=[1], label_correlation=0.75,\n",
    "                       return_missing_mask=True,\n",
    "                       random_state=42)\n",
    "\n",
    "print X, mm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_mask[y!=1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_values(data, target, missing_fraction=0.0,\n",
    "            missing_mask=mm,\n",
    "            return_missing_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rf_with_impute.fit(data, target)\n",
    "\n",
    "#rf_missing_val.estimators_[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pygraphviz as pgv\n",
    "import networkx as nx\n",
    "import pygraphviz\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from StringIO import StringIO\n",
    "from io import BytesIO\n",
    "\n",
    "def get_graph(dtc, n_classes, feat_names=None, size=[7, 7], max_depth=10):\n",
    "    dot_file = StringIO()\n",
    "    image_file = BytesIO()\n",
    "\n",
    "    # Get the dot graph of our decision tree\n",
    "    export_graphviz(dtc, out_file=dot_file, feature_names=feat_names,\n",
    "                    rounded=True, filled=True,\n",
    "                    special_characters=True,\n",
    "                    class_names=map(str, range(1, n_classes+1)),\n",
    "                    max_depth=max_depth)\n",
    "    dot_file.seek(0)\n",
    "\n",
    "    # Convert this dot graph into an image\n",
    "    g = pygraphviz.AGraph(dot_file.read())\n",
    "    g.layout('dot')\n",
    "    # g.draw doesn't work when the image object doesn't have a name (with a proper extension)\n",
    "    image_file.name = \"image.png\"\n",
    "    image_file.seek(0)\n",
    "    g.draw(path=image_file)\n",
    "    image_file.seek(0)\n",
    "\n",
    "    # Plot it\n",
    "    plt.figure().set_size_inches(*size)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.imread(fname=image_file))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:, 0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dtc = rf_with_impute.steps[1][1].estimators_[0]\n",
    "#dtc2= rf_miss_val.estimators_[4]\n",
    "print np.isnan(X).mean(), missing_mask.mean()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, missing_values='NaN')\n",
    "#dtc = rf_miss_val.fit(X, y).estimators_[1]\n",
    "dtc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_graph(dtc, n_classes=len(np.unique(y)),\n",
    "          feat_names=np.arange(X.shape[1]), size=[100, 200], max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_miss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_score = np.load('baseline_score.npy')\n",
    "missing_fraction_range = np.load('missing_fraction_range.npy')\n",
    "scores_missing = np.load('scores_missing.npy')\n",
    "scores_impute = np.load('scores_impute.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.plot(missing_fraction_range, seconds_missing, '.--', color='r', label='RF MV enabled')\n",
    "plt.plot(missing_fraction_range, seconds_impute, '.--', color='b', label='RF+imputer')\n",
    "plt.axhline(35, label='RF w/No missing', color='k')\n",
    "#for sample_pt in missing_fraction_range:\n",
    "#    plt.axvline(sample_pt, linestyle='--', color='g')\n",
    "plt.xlabel('Missing fraction')\n",
    "plt.ylabel('Time taken for cross_val_score using 3 iterations of StratifiedShuffleSplit in seconds')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "adult = fetch_mldata('yeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_feats = np.load('cat_feats.npy').tolist()\n",
    "feat_names = np.load('feat_names.npy').tolist()\n",
    "data = np.load('data.npy')\n",
    "target = np.load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging missing value support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toy data which will send all the missing values to the right at the root node\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = np.array(\n",
    "        [[np.nan],\n",
    "         [np.nan],\n",
    "         [np.nan],\n",
    "         [np.nan],\n",
    "         [0],\n",
    "         [1],\n",
    "         [2],\n",
    "         [3],\n",
    "         [12],\n",
    "         [13],\n",
    "         [10],\n",
    "         [11],\n",
    "         [12],\n",
    "         [13],\n",
    "         [14]])\n",
    "\n",
    "y = np.array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_graph(DecisionTreeClassifier(missing_values='NaN').fit(X, y),\n",
    "          n_classes=3, size=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# pylint: disable=too-many-arguments, too-many-locals, invalid-name, fixme\n",
    "\"\"\"Scikit-Learn Wrapper interface for XGBoost.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "from xgboost.core import Booster, DMatrix, XGBoostError\n",
    "from xgboost.training import train\n",
    "\n",
    "from xgboost.compat import (SKLEARN_INSTALLED, XGBModelBase,\n",
    "                            XGBClassifierBase, XGBRegressorBase, LabelEncoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbrf = XGBRFClassifier(n_estimators=n_estimators,\n",
    "                        nthread=n_jobs,\n",
    "                        max_depth=100,\n",
    "                        missing=np.nan,\n",
    "                        objective='multiclass:logistic',\n",
    "                        subsample=0.6,\n",
    "                        seed=random_state,\n",
    "                        base_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(xgbrf, data, target, cv=cv, fit_params={'eval_metric': 'auc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_miss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
