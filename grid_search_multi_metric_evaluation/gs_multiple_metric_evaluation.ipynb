{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator_score_test_mean</th>\n",
       "      <th>estimator_score_test_rank</th>\n",
       "      <th>estimator_score_test_split_0</th>\n",
       "      <th>estimator_score_test_split_1</th>\n",
       "      <th>estimator_score_test_split_2</th>\n",
       "      <th>estimator_score_test_std</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.270179</td>\n",
       "      <td>3</td>\n",
       "      <td>7.731211</td>\n",
       "      <td>9.098761</td>\n",
       "      <td>10.187935</td>\n",
       "      <td>1.005097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.473821</td>\n",
       "      <td>1</td>\n",
       "      <td>17.931207</td>\n",
       "      <td>14.106300</td>\n",
       "      <td>15.344608</td>\n",
       "      <td>1.593522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.379306</td>\n",
       "      <td>4</td>\n",
       "      <td>-21.095093</td>\n",
       "      <td>-8.870404</td>\n",
       "      <td>-7.965071</td>\n",
       "      <td>5.987581</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302800</td>\n",
       "      <td>2</td>\n",
       "      <td>9.500712</td>\n",
       "      <td>7.369996</td>\n",
       "      <td>13.409303</td>\n",
       "      <td>2.500895</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator_score_test_mean  estimator_score_test_rank  \\\n",
       "0                   0.270179                          3   \n",
       "1                   0.473821                          1   \n",
       "2                  -0.379306                          4   \n",
       "3                   0.302800                          2   \n",
       "\n",
       "   estimator_score_test_split_0  estimator_score_test_split_1  \\\n",
       "0                      7.731211                      9.098761   \n",
       "1                     17.931207                     14.106300   \n",
       "2                    -21.095093                     -8.870404   \n",
       "3                      9.500712                      7.369996   \n",
       "\n",
       "   estimator_score_test_split_2  estimator_score_test_std param_degree  \\\n",
       "0                     10.187935                  1.005097          NaN   \n",
       "1                     15.344608                  1.593522          NaN   \n",
       "2                     -7.965071                  5.987581            2   \n",
       "3                     13.409303                  2.500895            3   \n",
       "\n",
       "  param_gamma param_kernel  \n",
       "0         0.1          rbf  \n",
       "1        0.01          rbf  \n",
       "2         NaN         poly  \n",
       "3         NaN         poly  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "gs = GridSearchCV(SVR(),\n",
    "                  param_grid=[{'kernel':['rbf'], 'gamma':[0.1, 0.01]},\n",
    "                              {'kernel':['poly'], 'degree':[2, 3]}])\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "pd.DataFrame(gs.fit(X, y).search_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvraghav93/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:729: DeprecationWarning: The grid_scores_ attribute is deprecated in favor of the more elaborate search_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.27018, std: 1.00510, params: {'kernel': 'rbf', 'gamma': 0.1},\n",
       " mean: 0.47382, std: 1.59352, params: {'kernel': 'rbf', 'gamma': 0.01},\n",
       " mean: -0.37931, std: 5.98758, params: {'kernel': 'poly', 'degree': 2},\n",
       " mean: 0.30280, std: 2.50089, params: {'kernel': 'poly', 'degree': 3}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvraghav93/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/rvraghav93/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.27018, std: 0.03340, params: {'kernel': 'rbf', 'gamma': 0.1},\n",
       " mean: 0.47382, std: 0.04121, params: {'kernel': 'rbf', 'gamma': 0.01},\n",
       " mean: -0.37931, std: 0.17260, params: {'kernel': 'poly', 'degree': 2},\n",
       " mean: 0.30280, std: 0.07655, params: {'kernel': 'poly', 'degree': 3}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV as GridSearchCVo\n",
    "gso = GridSearchCVo(SVR(), param_grid=[{'kernel':['rbf'], 'gamma':[0.1, 0.01]},\n",
    "                                       {'kernel':['poly'], 'degree':[2, 3]}])\n",
    "gso.fit(X, y).grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neither of the following two estimators inherit from BaseEstimator,\n",
    "# to test hyperparameter search on user-defined classifiers.\n",
    "class MockClassifier(object):\n",
    "    \"\"\"Dummy classifier to test the parameter search algorithms\"\"\"\n",
    "    def __init__(self, foo_param=0):\n",
    "        self.foo_param = foo_param\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, T):\n",
    "        return T.shape[0]\n",
    "\n",
    "    predict_proba = predict\n",
    "    decision_function = predict\n",
    "    transform = predict\n",
    "\n",
    "    def score(self, X=None, Y=None):\n",
    "        if self.foo_param > 1:\n",
    "            score = 1.\n",
    "        else:\n",
    "            score = 0.\n",
    "        return score\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'foo_param': self.foo_param}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.foo_param = params['foo_param']\n",
    "        return self\n",
    "\n",
    "# Test that the best estimator contains the right value for foo_param\n",
    "clf = MockClassifier()\n",
    "grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]})\n",
    "# make sure it selects the smallest parameter in case of ties\n",
    "grid_search.fit(X, y)\n",
    "grid_search.best_estimator_.foo_param == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator_score_test_mean</th>\n",
       "      <th>estimator_score_test_rank</th>\n",
       "      <th>estimator_score_test_split_0</th>\n",
       "      <th>estimator_score_test_split_1</th>\n",
       "      <th>estimator_score_test_split_2</th>\n",
       "      <th>estimator_score_test_std</th>\n",
       "      <th>param_foo_param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator_score_test_mean  estimator_score_test_rank  \\\n",
       "0                        0.0                          3   \n",
       "1                        1.0                          1   \n",
       "2                        1.0                          2   \n",
       "\n",
       "   estimator_score_test_split_0  estimator_score_test_split_1  \\\n",
       "0                           0.0                           0.0   \n",
       "1                          34.0                          33.0   \n",
       "2                          34.0                          33.0   \n",
       "\n",
       "   estimator_score_test_split_2  estimator_score_test_std param_foo_param  \n",
       "0                           0.0                  0.000000               1  \n",
       "1                          33.0                  0.471405               2  \n",
       "2                          33.0                  0.471405               3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.search_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argsort(grid_search.search_results_[\"estimator_score_test_mean\"], kind='heapsort')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.foo_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvraghav93/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:729: DeprecationWarning: The grid_scores_ attribute is deprecated in favor of the more elaborate search_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969696969697 32.9696969697\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b39bf3b39db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mcorrect_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mcorrect_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# test that correct scores are used\n",
    "clf = LinearSVC(random_state=0)\n",
    "X, y = make_blobs(random_state=0, centers=2)\n",
    "Cs = [.1, 1, 10]\n",
    "for score in ['f1', 'roc_auc']:\n",
    "    grid_search = GridSearchCV(clf, {'C': Cs}, scoring=score)\n",
    "    grid_search.fit(X, y)\n",
    "    cv = StratifiedKFold(n_folds=3)\n",
    "    for C, scores in zip(Cs, grid_search.grid_scores_):\n",
    "        clf.set_params(C=C)\n",
    "        scores = scores[2]  # get the separate runs from grid scores\n",
    "        i = 0\n",
    "        for train, test in cv.split(X, y):\n",
    "            clf.fit(X[train], y[train])\n",
    "            if score == \"f1\":\n",
    "                correct_score = f1_score(y[test], clf.predict(X[test]))\n",
    "            elif score == \"roc_auc\":\n",
    "                dec = clf.decision_function(X[test])\n",
    "                correct_score = roc_auc_score(y[test], dec)\n",
    "            \n",
    "            print correct_score, scores[i]\n",
    "            assert correct_score == scores[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_test_mean</th>\n",
       "      <th>f1_test_rank</th>\n",
       "      <th>f1_test_split_0</th>\n",
       "      <th>f1_test_split_1</th>\n",
       "      <th>f1_test_split_2</th>\n",
       "      <th>f1_test_std</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.911374</td>\n",
       "      <td>3</td>\n",
       "      <td>32.969697</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>30.967742</td>\n",
       "      <td>2.391957</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923296</td>\n",
       "      <td>2</td>\n",
       "      <td>33.028571</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>30.967742</td>\n",
       "      <td>1.921585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924340</td>\n",
       "      <td>1</td>\n",
       "      <td>33.028571</td>\n",
       "      <td>29.405405</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.586510</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_test_mean  f1_test_rank  f1_test_split_0  f1_test_split_1  \\\n",
       "0      0.911374             3        32.969697        27.200000   \n",
       "1      0.923296             2        33.028571        28.333333   \n",
       "2      0.924340             1        33.028571        29.405405   \n",
       "\n",
       "   f1_test_split_2  f1_test_std param_C  \n",
       "0        30.967742     2.391957     0.1  \n",
       "1        30.967742     1.921585       1  \n",
       "2        30.000000     1.586510      10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.search_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foobar(a, b=5, c=4):\n",
    "    print a, b, c\n",
    "    return 5\n",
    "    \n",
    "def boobar():\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foobar_with_a_set = partial(foobar, a=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 4\n"
     ]
    }
   ],
   "source": [
    "for fn in [foobar_with_a_set, boobar]:\n",
    "    assert 5 == fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 5 3\n"
     ]
    }
   ],
   "source": [
    "foobar(6, c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
