{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 correlated and 0 non-correlated new missing values introduced.\n",
      "After dropping 10% of values when class label(s) are array([0])\n",
      "\n",
      "y \t X\n",
      "------------------------\n",
      "0 \t [ nan   1.   2.]\n",
      "1 \t [ 3.  4.  5.]\n",
      "1 \t [ 6.  7.  8.]\n",
      "1 \t [ 9.  0.  1.]\n",
      "1 \t [ 2.  3.  4.]\n",
      "0 \t [ 8.  9.  8.]\n",
      "0 \t [ 1.  0.  5.]\n",
      "0 \t [ nan   8.  nan]\n",
      "0 \t [  5.  nan   3.]\n",
      "1 \t [ 2.  1.  1.]\n",
      "2 \t [ 3.  4.  5.]\n",
      "2 \t [ 2.  3.  4.]\n",
      "2 \t [ 8.  9.  8.]\n",
      "2 \t [ 1.  0.  5.]\n",
      "2 \t [ 7.  8.  9.]\n",
      "\n",
      "\n",
      "\n",
      "There are 5 correlated and 0 non-correlated new missing values introduced.\n",
      "After dropping another 10% of values when class label(s) are array([0])\n",
      "\n",
      "y \t X\n",
      "------------------------\n",
      "0 \t [ nan  nan   2.]\n",
      "1 \t [ 3.  4.  5.]\n",
      "1 \t [ 6.  7.  8.]\n",
      "1 \t [ 9.  0.  1.]\n",
      "1 \t [ 2.  3.  4.]\n",
      "0 \t [ nan   9.   8.]\n",
      "0 \t [ nan   0.   5.]\n",
      "0 \t [ nan   8.  nan]\n",
      "0 \t [ nan  nan  nan]\n",
      "1 \t [ 2.  1.  1.]\n",
      "2 \t [ 3.  4.  5.]\n",
      "2 \t [ 2.  3.  4.]\n",
      "2 \t [ 8.  9.  8.]\n",
      "2 \t [ 1.  0.  5.]\n",
      "2 \t [ 7.  8.  9.]\n",
      "\n",
      "\n",
      "\n",
      "There are 4 correlated and 0 non-correlated new missing values introduced.\n",
      "NOTE that the missing_values are set. Only the missing mask is updated...\n",
      "y \t missing_mask\n",
      "------------------------\n",
      "0 \t [ True  True False]\n",
      "1 \t [ True False False]\n",
      "1 \t [False False False]\n",
      "1 \t [False False False]\n",
      "1 \t [ True False  True]\n",
      "0 \t [ True False False]\n",
      "0 \t [ True False False]\n",
      "0 \t [ True False  True]\n",
      "0 \t [ True  True  True]\n",
      "1 \t [False  True False]\n",
      "2 \t [False False False]\n",
      "2 \t [False False False]\n",
      "2 \t [False False False]\n",
      "2 \t [False False False]\n",
      "2 \t [False False False]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The X is not modified\n",
      "y \t X\n",
      "------------------------\n",
      "0 \t [ nan  nan   2.]\n",
      "1 \t [ 3.  4.  5.]\n",
      "1 \t [ 6.  7.  8.]\n",
      "1 \t [ 9.  0.  1.]\n",
      "1 \t [ 2.  3.  4.]\n",
      "0 \t [ nan   9.   8.]\n",
      "0 \t [ nan   0.   5.]\n",
      "0 \t [ nan   8.  nan]\n",
      "0 \t [ nan  nan  nan]\n",
      "1 \t [ 2.  1.  1.]\n",
      "2 \t [ 3.  4.  5.]\n",
      "2 \t [ 2.  3.  4.]\n",
      "2 \t [ 8.  9.  8.]\n",
      "2 \t [ 1.  0.  5.]\n",
      "2 \t [ 7.  8.  9.]\n",
      "\n",
      "\n",
      "\n",
      "After manually updating the new missing values\n",
      "y \t X\n",
      "------------------------\n",
      "0 \t [ nan  nan   2.]\n",
      "1 \t [ nan   4.   5.]\n",
      "1 \t [ 6.  7.  8.]\n",
      "1 \t [ 9.  0.  1.]\n",
      "1 \t [ nan   3.  nan]\n",
      "0 \t [ nan   9.   8.]\n",
      "0 \t [ nan   0.   5.]\n",
      "0 \t [ nan   8.  nan]\n",
      "0 \t [ nan  nan  nan]\n",
      "1 \t [  2.  nan   1.]\n",
      "2 \t [ 3.  4.  5.]\n",
      "2 \t [ 2.  3.  4.]\n",
      "2 \t [ 8.  9.  8.]\n",
      "2 \t [ 1.  0.  5.]\n",
      "2 \t [ 7.  8.  9.]\n",
      "\n",
      "\n",
      "\n",
      "There are 0 correlated and 5 non-correlated new missing values introduced.\n",
      "y \t X\n",
      "------------------------\n",
      "0 \t [ nan  nan   2.]\n",
      "1 \t [ nan   4.   5.]\n",
      "1 \t [ 6.  7.  8.]\n",
      "1 \t [  9.   0.  nan]\n",
      "1 \t [ nan   3.  nan]\n",
      "0 \t [ nan   9.   8.]\n",
      "0 \t [ nan   0.   5.]\n",
      "0 \t [ nan   8.  nan]\n",
      "0 \t [ nan  nan  nan]\n",
      "1 \t [ nan  nan   1.]\n",
      "2 \t [ nan   4.   5.]\n",
      "2 \t [ 2.  3.  4.]\n",
      "2 \t [  8.  nan   8.]\n",
      "2 \t [ 1.  0.  5.]\n",
      "2 \t [ nan   8.   9.]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import drop_values\n",
    "import numpy as np\n",
    "\n",
    "X = [[0, 1, 2],\n",
    "     [3, 4, 5],\n",
    "     [6, 7, 8],\n",
    "     [9, 0, 1],\n",
    "     [2, 3, 4],\n",
    "     [8, 9, 8],\n",
    "     [1, 0, 5],\n",
    "     [7, 8, 9],\n",
    "     [5, 4, 3],\n",
    "     [2, 1, 1],\n",
    "     [3, 4, 5],\n",
    "     [2, 3, 4],\n",
    "     [8, 9, 8],\n",
    "     [1, 0, 5],\n",
    "     [7, 8, 9],]\n",
    "y = [0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2]\n",
    "\n",
    "# Drop 10% of values across all features for samples\n",
    "# where the target class label is randomly chosen\n",
    "\n",
    "X, y, mm, labels = drop_values(X, y,\n",
    "                               drop_fraction=0.1,\n",
    "                               return_missing_mask=True,\n",
    "                               return_labels=True,\n",
    "                               copy=False,\n",
    "                               verbose=True,\n",
    "                               random_state=42)\n",
    "\n",
    "print(\"After dropping 10%% of values when class label(s) are %r\\n\" % labels)\n",
    "print(\"y \\t X\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', X[i])\n",
    "    \n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "# Drop 10% of values across all features for samples\n",
    "# where the target class label is same as what was chosen before\n",
    "\n",
    "# NOTE We can now pass the missing mask from the previous step\n",
    "# to avoid it getting recomputed.\n",
    "\n",
    "X, y, mm = drop_values(X, y, missing_mask=mm,\n",
    "                       drop_fraction=0.2,\n",
    "                       labels=labels,\n",
    "                       return_labels=False,\n",
    "                       return_missing_mask=True,\n",
    "                       copy=False,\n",
    "                       verbose=True,\n",
    "                       random_state=42)\n",
    "\n",
    "print(\"After dropping another 10%% of values when class label(s) are %r\\n\" % labels)\n",
    "print(\"y \\t X\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', X[i])\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "# Now drop another 10%, but this time from class 0\n",
    "# This time let us not modify X inplace and instead return the missing mask and \n",
    "# manually set the missing_values\n",
    "\n",
    "# This time we are not passing the previous missing_mask and allowing it to get computed\n",
    "# on the fly\n",
    "\n",
    "# Let us store the old missing mask\n",
    "mm_old = mm.copy()\n",
    "\n",
    "X, y, mm = drop_values(X, y,\n",
    "                       drop_fraction=0.3,\n",
    "                       # Explicitly specify we want missing values correlated to class 0\n",
    "                       labels=[1, ],\n",
    "                       return_labels=False,\n",
    "                       return_missing_mask=True,\n",
    "                       missing_mask_only=True,\n",
    "                       copy=False,\n",
    "                       verbose=True,\n",
    "                       random_state=42)\n",
    "\n",
    "print(\"NOTE that the missing_values are set. Only the missing mask is updated...\")\n",
    "print(\"y \\t missing_mask\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', mm[i])\n",
    "    \n",
    "print('\\n\\n')\n",
    "print('\\nThe X is not modified')\n",
    "print(\"y \\t X\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', X[i])\n",
    "    \n",
    "print('\\n\\n')\n",
    "\n",
    "    \n",
    "# Manually update the missing values from the mask\n",
    "# only for the newly missing values\n",
    "\n",
    "mm_new = mm_old ^ mm\n",
    "X[mm_new] = np.nan\n",
    "\n",
    "print(\"After manually updating the new missing values\")\n",
    "print(\"y \\t X\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', X[i])\n",
    "    \n",
    "print('\\n\\n')\n",
    "\n",
    "# Now let us add additional 10% of random missing values\n",
    "\n",
    "X, y = drop_values(X, y,\n",
    "                   drop_fraction=0.4,\n",
    "                   # Explicitly specify we want missing values correlated to class 0\n",
    "                   label_correlation=0,\n",
    "                   copy=False,\n",
    "                   verbose=True,\n",
    "                   random_state=42)\n",
    "\n",
    "print(\"y \\t X\")\n",
    "print(\"------------------------\")\n",
    "for i in range(y.shape[0]):\n",
    "    print(y[i], '\\t', X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continuous-multioutput'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_target([[0.2, 0.2], [0.3, 0.5], [0.5, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-071a02da8f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                            copy=False, random_state=42)\n\u001b[1;32m     17\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.datasets import drop_values\n",
    ">>> X = [[0, 1, 2],\n",
    "...      [3, 4, 5],\n",
    "...      [6, 7, 8],\n",
    "...      [9, 0, 1],\n",
    "...      [2, 3, 4],\n",
    "...      [8, 9, 8],\n",
    "...      [1, 0, 5],\n",
    "...      [7, 8, 9],\n",
    "...      [5, 4, 3],\n",
    "...      [2, 1, 1],\n",
    "...      [1, 2, 3]]\n",
    ">>> y = [0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]\n",
    ">>> X, y, labels = drop_values(X, y, drop_fraction=0.1,\n",
    "...                            n_labels=1, return_labels=True,\n",
    "...                            copy=False, random_state=42)\n",
    ">>> labels\n",
    "array([1])\n",
    ">>> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22749999999999995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.var([11, 12, 13, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "allclose() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b2bda38e7d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: allclose() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import drop_values\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.utils.testing import assert_array_equal\n",
    "from sklearn.utils.testing import assert_array_almost_equal\n",
    "from sklearn.utils.testing import assert_equal\n",
    "from sklearn.utils.testing import assert_less\n",
    "from sklearn.utils.testing import assert_true\n",
    "from sklearn.utils.testing import assert_almost_equal\n",
    "from sklearn.utils.testing import assert_array_almost_equal\n",
    "\n",
    "def test_value_dropper_mcar_clf():\n",
    "    X, y = make_classification(n_samples=100, n_classes=4, n_features=5,\n",
    "                               n_informative=5, n_redundant=0, n_repeated=0,\n",
    "                               random_state=0)\n",
    "\n",
    "    # Inplace dropping of values; 0 correlation case.\n",
    "    _, _ = drop_values(X, y,\n",
    "                       drop_fraction=0.3, label_correlation=0,\n",
    "                       missing_values=np.nan, random_state=0)\n",
    "\n",
    "    # Check the drop fraction\n",
    "    assert_almost_equal(np.isnan(X).ravel().sum() / 500., 0.3)\n",
    "\n",
    "    # Check that there is no correlation (The missing values are spread equally\n",
    "    # between different label values)\n",
    "    n_dropped_per_label = [(np.isnan(X)[y==lbl]).ravel().sum() for lbl in np.unique(y)]\n",
    "    n_samples_per_label = np.bincount(y) * 5\n",
    "    # That is all the per label missing fraction should be close to 0.3\n",
    "    per_label_drop_fraction = (n_dropped_per_label / n_samples_per_label.astype(np.float))\n",
    "    assert_almost_equal(per_label_drop_fraction.mean(), 0.3)\n",
    "    assert_less(np.std(per_label_drop_fraction), 0.05)\n",
    "\n",
    "    # Let us drop 0.3 more fraction of values. This time not inplace\n",
    "    X_old = X.copy()\n",
    "    X_more_dropped, _ = drop_values(\n",
    "        X, y, drop_fraction=0.6, label_correlation=0,\n",
    "        missing_values=\"NaN\",\n",
    "        copy=True, random_state=0)\n",
    "\n",
    "    assert_almost_equal(X, X_old)\n",
    "    try:\n",
    "        assert_almost_equal(X_more_dropped, X)\n",
    "    except AssertionError as e:\n",
    "        assert_true(\"nan location mismatch\" in str(e))\n",
    "\n",
    "    # Check that there is no correlation (The missing values are spread equally\n",
    "    # between different label values)\n",
    "    n_dropped_per_label = [(np.isnan(X_more_dropped)[y==lbl]).ravel().sum() for lbl in np.unique(y)]\n",
    "    n_samples_per_label = np.bincount(y) * 5\n",
    "    # That is all the per label missing fraction should now be close to 0.6\n",
    "    per_label_drop_fraction = (n_dropped_per_label / n_samples_per_label.astype(np.float))\n",
    "    assert_almost_equal(per_label_drop_fraction.mean(), 0.6)\n",
    "    assert_less(np.std(per_label_drop_fraction), 0.05)\n",
    "    \n",
    "\n",
    "def test_value_dropper_mcar_reg():\n",
    "    X, y = make_regression(n_samples=100, n_classes=4, n_features=5,\n",
    "                           n_informative=5, n_redundant=0, n_repeated=0,\n",
    "                           random_state=0)\n",
    "\n",
    "    # Inplace dropping of values; 0 correlation case.\n",
    "    _, _ = drop_values(X, y,\n",
    "                       drop_fraction=0.3, label_correlation=0,\n",
    "                       missing_values=np.nan, random_state=0)\n",
    "\n",
    "    # Check the drop fraction\n",
    "    assert_almost_equal(np.isnan(X).ravel().sum() / 500., 0.3)\n",
    "\n",
    "    # Check that there is no correlation (The missing values are spread equally\n",
    "    # between different target values)\n",
    "    \n",
    "    # That is all the per label missing fraction should be close to 0.3\n",
    "    per_label_drop_fraction = (n_dropped_per_label / n_samples_per_label.astype(np.float))\n",
    "    assert_almost_equal(per_label_drop_fraction.mean(), 0.3)\n",
    "    assert_less(np.std(per_label_drop_fraction), 0.05)\n",
    "\n",
    "    # Let us drop 0.3 more fraction of values. This time not inplace\n",
    "    X_old = X.copy()\n",
    "    X_more_dropped, _ = drop_values(\n",
    "        X, y, drop_fraction=0.6, label_correlation=0,\n",
    "        missing_values=\"NaN\",\n",
    "        copy=True, random_state=0)\n",
    "\n",
    "    assert_almost_equal(X, X_old)\n",
    "    try:\n",
    "        assert_almost_equal(X_more_dropped, X)\n",
    "    except AssertionError as e:\n",
    "        assert_true(\"nan location mismatch\" in str(e))\n",
    "\n",
    "    # Check that there is no correlation (The missing values are spread equally\n",
    "    # between different label values)\n",
    "    n_dropped_per_label = [(np.isnan(X_more_dropped)[y==lbl]).ravel().sum() for lbl in np.unique(y)]\n",
    "    n_samples_per_label = np.bincount(y) * 5\n",
    "    # That is all the per label missing fraction should now be close to 0.6\n",
    "    per_label_drop_fraction = (n_dropped_per_label / n_samples_per_label.astype(np.float))\n",
    "    assert_almost_equal(per_label_drop_fraction.mean(), 0.6)\n",
    "    assert_less(np.std(per_label_drop_fraction), 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
