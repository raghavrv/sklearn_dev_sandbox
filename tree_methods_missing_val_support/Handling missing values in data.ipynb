{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================================================\n",
    "Imputing missing values before building an estimator\n",
    "======================================================\n",
    "\n",
    "This example shows techinques to handle missing values instead of discarding\n",
    "the samples containing any missing value.\n",
    "\n",
    "The first technique used to handle missing values is by imputing the missing values\n",
    "based on the feature-wise statistic. Note that imputing does not always improve\n",
    "the predictions, so please check via cross-validation. Sometimes dropping rows\n",
    "or using marker values is more effective.\n",
    "\n",
    "In this example, we artificially mark some of the elements in complete\n",
    "dataset as missing. Then we estimate performance using the complete dataset,\n",
    "dataset without the missing samples, after imputation without the indicator\n",
    "matrix and imputation with the indicator matrix for the missing values.\n",
    "\n",
    "The imputation can be done by replacing the missing values by the mean, the\n",
    "median or the most frequent value using the ``strategy`` hyper-parameter.\n",
    "The median is a more robust estimator for data with high magnitude variables\n",
    "which could dominate results (otherwise known as a 'long tail').\n",
    "\n",
    "Script output::\n",
    "\n",
    "  Score with the complete dataset = 0.56\n",
    "  Score without the samples containing missing values = 0.48\n",
    "  Score after imputation of the missing values = 0.55\n",
    "  Score after imputation with indicator features = 0.57\n",
    "  Score \n",
    "\n",
    "In this case, imputing helps the classifier get close to the original score.\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "# Author:  Nicolas Tr√©segnie <nicolas.tresegnie@gmail.com>\n",
    "#          David Fletcher <madder_dan@yahoo.co.uk>\n",
    "#          Lars Buitinck <l.j.buitinck@uva.nl>\n",
    "#          Gilles Louppe <g.louppe@gmail.com>\n",
    "#          Maniteja Nandana <manitejanmt@gmail.com>\n",
    "#          Raghav R V <rvraghav93@gmail.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "dataset = load_boston()\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "print(\"Score with the complete dataset = %.2f\" % score)\n",
    "\n",
    "# Add missing values in 75% of the lines\n",
    "missing_rate = 0.75\n",
    "n_missing_samples = int(n_samples * missing_rate)\n",
    "missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
    "                                      dtype=np.bool),\n",
    "                             np.ones(n_missing_samples,\n",
    "                                     dtype=np.bool)))\n",
    "rng.shuffle(missing_samples)\n",
    "missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "\n",
    "# Estimate the score without the lines containing missing values\n",
    "X_filtered = X_full[~missing_samples, :]\n",
    "y_filtered = y_full[~missing_samples]\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_filtered, y_filtered).mean()\n",
    "print(\"Score without the samples containing missing values = %.2f\" % score)\n",
    "\n",
    "# Estimate the score after imputation of the missing values\n",
    "X_missing = X_full.copy()\n",
    "X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
    "y_missing = y_full.copy()\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
    "                                                       n_estimators=100))])\n",
    "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
    "print(\"Score after imputation of the missing values = %.2f\" % score)\n",
    "\n",
    "# Estimate score after imputation of the missing values with indicator matrix\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0, add_indicator_features=True)),\n",
    "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
    "                                                       n_estimators=100))])\n",
    "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
    "print(\"Score after imputation with indicator features = %.2f\" % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
