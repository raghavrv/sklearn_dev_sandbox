{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# NOTE The add_indicator_feature is not in sklearn 0.18.0 This is a patched version for benchmarking...\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from scipy.io.arff import loadarff as scipy_loadarff\n",
    "from arff import load as liac_loadarff\n",
    "\n",
    "# https://github.com/raghavrv/pyarff\n",
    "# NOTE pyarff is very much experimental and is not finished fully yet\n",
    "# scipy arff is a bit slow but doesn't encode categories.\n",
    "# LIAC is another arff reader that works on sparse too but sometimes breaks with\n",
    "# datasets that surround data with quotes\n",
    "import pyarff\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pygraphviz as pgv\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def get_graph(dtc, n_classes, feat_names=None, size=[7, 7]):\n",
    "    # Get the dot graph of our decision tree\n",
    "    tree_dot = export_graphviz(\n",
    "        dtc, out_file=None, feature_names=feat_names, rounded=True, filled=True,\n",
    "        special_characters=True, class_names=list(map(str, range(n_classes))), max_depth=10)\n",
    "    # Convert this dot graph into an image\n",
    "    g = pgv.AGraph(tree_dot)\n",
    "    g.layout('dot')\n",
    "    g.draw(path='temp.png')\n",
    "    # Plot it\n",
    "    plt.figure().set_size_inches(*size)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.imread(fname='temp.png'))\n",
    "    plt.show()\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "all_datasets = OrderedDict()\n",
    "\n",
    "def print_progress_bar(n):\n",
    "    n = int(n)\n",
    "    print(\"\\r\" + \"█\" + (\"█\" *  n) + (\"-\" * (100 - n)) + \"█ %d%%\" % n,\n",
    "          end=\"\" if n != 100 else \"\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Demo of DecisionTreeClassifier handling missing values natively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(missing_values='NaN')\n",
    "\n",
    "# Class 0 if missing or <= 3.5\n",
    "# Class 1 if not missing and > 3.5\n",
    "dtc.fit([[np.nan,], [np.nan,], [np.nan,], [1,], [2,], [3,], [4,], [5,], [6,]],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
    "print(dtc.predict([[np.nan], [0,], [7,], [3.6,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = get_graph(dtc, n_classes=2, size=[3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some benchmarks on real world datasets that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Anneal dataset - http://www.openml.org/d/2\n",
    "\n",
    "meta1, data1 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/anneal.arff')\n",
    "data1 = data1[:-1]  # The last one seems to have a wrong class label. Check pyarff.\n",
    "X, y = data1[:, :-1], data1[:, -1]\n",
    "all_datasets['anneal'] = (X, y)\n",
    "\n",
    "np.bincount(y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KDDCUP09_churn - http://www.openml.org/d/1112\n",
    "\n",
    "# start = time.time()\n",
    "# data = scpy_arff_load('/home/raghavrv/code/datasets/arff/KDDCup09_churn.arff')[0]\n",
    "# print(\"KDDCUP09_churn ARFF dataset loaded in %0.8fs\" % (time.time() - start))\n",
    "# X = np.array([np.array(list(data_i))[:190] for data_i in data]).astype(float)\n",
    "# y = np.array([data_i[-1] for data_i in data]).astype(int)\n",
    "\n",
    "meta2, data2 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/KDDCup09_churn.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data2[:, :-1], data2[:, -1]\n",
    "all_datasets['KDDCUP09_churn'] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KDDCUP09_appetency - http://www.openml.org/d/1111\n",
    "\n",
    "meta3, data3 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/KDDCup09_appetency.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data3[:, :-1], data3[:, -1]\n",
    "all_datasets['KDDCUP09_appetency'] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KDDCUP09_upselling - http://www.openml.org/d/1114\n",
    "\n",
    "meta4, data4 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/KDDCup09_upselling.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data4[:, :-1], data4[:, -1]\n",
    "all_datasets['KDDCUP09_upselling'] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CSJ - http://www.openml.org/d/23380\n",
    "\n",
    "meta5, data5 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/cjs.arff',\n",
    "                                        encode_nominals=True)\n",
    "\n",
    "target_index = meta5['attributes'][b'TR']['order']\n",
    "X = np.hstack((data5[:, :target_index], data5[:, target_index+1:])).astype(float)\n",
    "y = data5[:, target_index].astype(int)\n",
    "all_datasets['cjs'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Soy Bean dataset - http://www.openml.org/d/42\n",
    "\n",
    "meta6, data6 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/soybean.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data6[:, :-1].astype(float), data6[:, -1].astype(int)\n",
    "y[-1] = 2  # The last label seems to not be loaded properly (Pyarff bug)\n",
    "all_datasets['soy_bean'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adult Census dataset - https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "meta, data = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/adult-census.arff',\n",
    "                                      encode_nominals=True)\n",
    "X, y = data[:, :-1].astype(float), data[:, -1].astype(int)\n",
    "all_datasets['adult_census'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lymphoma 2 classes - http://www.openml.org/d/1101\n",
    "\n",
    "meta7, data7 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/lymphoma_2classes.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data7[:, :-1].astype(float), data7[:, -1].astype(int)\n",
    "all_datasets['lymphoma_2classes'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lymphoma 9 classes - http://www.openml.org/d/1102\n",
    "\n",
    "\n",
    "meta8, data8 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/lymphoma_9classes.arff',\n",
    "                                        encode_nominals=True)\n",
    "X, y = data8[:, :-1].astype(float), data8[:, -1].astype(int)\n",
    "all_datasets['lymphoma_9classes'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KDD98 - http://www.openml.org/d/23513\n",
    "\n",
    "meta9, data9 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/kdd98_data.arff',\n",
    "                                        encode_nominals=True)\n",
    "target_index = meta9['attribute_names_in_order'].index(b'TARGET_B')\n",
    "X = np.hstack([data9[:, :target_index], data9[:, target_index+1:]]).astype(float)\n",
    "y = data9[:, target_index].astype(int)\n",
    "all_datasets['kdd98'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Colleges US News binarized - http://www.openml.org/d/930\n",
    "\n",
    "# data10_ = scipy_loadarff('/home/raghavrv/code/datasets/arff/colleges_usnews.arff')[0]\n",
    "# X_ = np.array([list(data_i) for data_i in data10_])[:-1]\n",
    "# y_ = np.array([data_i[-1] for data_i in data10_])[:-1]\n",
    "\n",
    "meta10, data10 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/colleges_usnews.arff',\n",
    "                                          encode_nominals=True)\n",
    "data10 = data10[:-1]  # The last one seems to have a wrong class label. Bug in pyarff.\n",
    "X, y = data10[:, :-1].astype(float), data10[:, -1].astype(int)\n",
    "all_datasets['colleges_usnews'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arrhythmia - http://www.openml.org/d/5\n",
    "\n",
    "meta11, data11 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/dataset_5_arrhythmia.arff',\n",
    "                                          encode_nominals=True)\n",
    "\n",
    "target_index = meta11['attributes'][b'class']['order']\n",
    "X = np.hstack((data11[:, :target_index], data11[:, target_index+1:])).astype(float)\n",
    "y = data11[:, target_index].astype(int)\n",
    "all_datasets['arrhythmia'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vote - http://www.openml.org/d/56\n",
    "\n",
    "meta12, data12 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/vote.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index = meta12['attributes'][b'Class']['order']\n",
    "X = np.hstack((data12[:, :target_index], data12[:, target_index+1:])).astype(float)\n",
    "y = data12[:, target_index].astype(int)\n",
    "all_datasets['vote'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pro Football Scores - http://www.openml.org/d/470\n",
    "\n",
    "meta13, data13 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/profb.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index = meta13['attributes'][b'Home/Away']['order']\n",
    "X = np.hstack((data13[:, :target_index], data13[:, target_index+1:])).astype(float)\n",
    "y = data13[:, target_index].astype(int)\n",
    "all_datasets['pro football scores'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mice Protein - http://www.openml.org/d/4550\n",
    "\n",
    "meta14, data14 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/mice.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index = meta14['attributes'][b'class']['order']\n",
    "X = np.hstack((data14[:, :target_index], data14[:, target_index+1:])).astype(float)\n",
    "y = data14[:, target_index].astype(int)\n",
    "all_datasets['mice_protein'] = (X, y)\n",
    "\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# IPUMS98 small - http://www.openml.org/d/381\n",
    "\n",
    "meta14, data14 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/ipums_la_98-small.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index = meta14['attributes'][b'movedin']['order']\n",
    "X = np.hstack((data14[:, :target_index], data14[:, target_index+1:])).astype(float)\n",
    "y = data14[:, target_index].astype(int)\n",
    "all_datasets['ipums_98'] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# IPUMS97 small - http://www.openml.org/d/381\n",
    "\n",
    "meta, data = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/ipums_la_97-small.arff',\n",
    "                                      encode_nominals=True)\n",
    "target_index = meta['attributes'][b'movedin']['order']\n",
    "X = np.hstack((data[:, :target_index], data[:, target_index+1:])).astype(float)\n",
    "y = data[:, target_index].astype(int)\n",
    "all_datasets['ipums_97'] = (X, y)\n",
    "\n",
    "class_count = np.bincount(y)\n",
    "classes = np.unique(y)\n",
    "print(list(zip(classes, class_count[classes.tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# IPUMS99 small - http://www.openml.org/d/381\n",
    "\n",
    "meta16, data16 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/arff/ipums_la_99-small.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index16 = meta16['attributes'][b'movedin']['order']\n",
    "X16 = np.hstack((data16[:, :target_index16], data16[:, target_index16+1:])).astype(float)\n",
    "y16 = data16[:, target_index16].astype(int)\n",
    "all_datasets['ipums_99'] = (X16, y16)\n",
    "\n",
    "class_count16 = np.bincount(y16)\n",
    "classes16 = np.unique(y16)\n",
    "print(list(zip(classes16, class_count16[classes16.tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 19) Census Income Dataset (Large) - http://sci2s.ugr.es/keel/dataset.php?cod=195\n",
    "\n",
    "meta17, data17 = pyarff.load_arff_dataset('/home/raghavrv/code/datasets/more_missing_datasets/census.arff',\n",
    "                                          encode_nominals=True)\n",
    "target_index17 = meta17['attributes'][b'Class']['order']\n",
    "X17 = np.hstack((data17[:, :target_index17], data17[:, target_index17+1:])).astype(float)\n",
    "y17 = data17[:, target_index17].astype(int)\n",
    "all_datasets['census_income_large'] = (X17, y17)\n",
    "\n",
    "class_count17 = np.bincount(y17)\n",
    "classes17 = np.unique(y17)\n",
    "print(list(zip(classes17, class_count17[classes17.tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 20) Higgs Boson challenge Kaggle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_train = np.loadtxt('/home/raghavrv/code/datasets/kaggle_higgs_challenge/training.csv',\n",
    "                     delimiter=',', unpack=True, skiprows=1, usecols=np.arange(1, 32)).T\n",
    "X_test = np.loadtxt('/home/raghavrv/code/datasets/kaggle_higgs_challenge/test.csv',\n",
    "                     delimiter=',', unpack=True, skiprows=1, usecols=np.arange(1, 31)).T\n",
    "y_train = np.loadtxt('/home/raghavrv/code/datasets/kaggle_higgs_challenge/training.csv',\n",
    "                  delimiter=',', unpack=True, skiprows=1, usecols=(32,), dtype=bytes)\n",
    "\n",
    "# Higgs Boson dataset represents unavailable data as -999\n",
    "X_train[X_train==-999.] = np.nan\n",
    "X_test[X_test==-999.] = np.nan\n",
    "\n",
    "sample_weight = X_train[:, -1]\n",
    "\n",
    "X_train = X_train[:, :-1]\n",
    "\n",
    "all_datasets['higgs_boson'] = (X_train, y_train, sample_weight)\n",
    "\n",
    "class_count = np.bincount((y_train == b's').astype(int))\n",
    "classes = np.unique(y_train)\n",
    "print(list(zip(classes, class_count[(classes == b's').astype(int).tolist()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark and Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_jobs = 8\n",
    "n_estimators = 50\n",
    "max_depth = None\n",
    "cv=StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "\n",
    "verbose=False\n",
    "\n",
    "print('n_jobs=%d'%n_jobs)\n",
    "\n",
    "all_results = OrderedDict()\n",
    "\n",
    "for n_estimators, max_depth, bootstrap in product((10, 50, 100), (10, 20, 30, None), (True, False)):\n",
    "    print()\n",
    "    print(\"=*\" * 50)\n",
    "    print(\"n_estimators=%d; max_depth=%s; bootstrap=%s\" % (n_estimators, str(max_depth), str(bootstrap)))\n",
    "    print(\"=*\" * 50)\n",
    "    print()\n",
    "\n",
    "    all_benchmarks = OrderedDict()\n",
    "    all_score_ranks = OrderedDict()\n",
    "    all_time_ranks = OrderedDict()\n",
    "    all_estimators = OrderedDict()\n",
    "\n",
    "    for dataset_desc, data in all_datasets.items():\n",
    "        if len(data) == 2:\n",
    "            sw = \"\"\n",
    "            X, y, sample_weight = data[0], data[1], None\n",
    "        else:\n",
    "            sw = \"\\nTraining with sample weights.\"\n",
    "            X, y, sample_weight = data\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        n_classes = np.unique(y).shape[0]\n",
    "        benchmarks = []  # Tuple of (<technique>, mean cross val score, total fit time)\n",
    "        estimators = []\n",
    "\n",
    "        missing_mask = np.isnan(X)\n",
    "        missing_samples, missing_features = np.where(missing_mask)\n",
    "        if verbose:\n",
    "            print(\"Dataset %s with %d samples and %d features. n_classes=%d; It has %0.4f%% values missing;%s\" \n",
    "                  % (dataset_desc, n_samples, n_features, n_classes,\n",
    "                     100. * (np.sum(missing_mask) / (n_samples * n_features)), sw))\n",
    "            print(\"====================================================================================================\\n\")\n",
    "        \n",
    "\n",
    "            print_progress_bar(0)\n",
    "\n",
    "        # 1) Estimate score with RFC natively handling missing values\n",
    "        estimator = RandomForestClassifier(random_state=0, n_jobs=n_jobs, bootstrap=bootstrap,\n",
    "                                           missing_values=\"NaN\", n_estimators=n_estimators,\n",
    "                                           max_depth=max_depth)\n",
    "        scores = cross_val_score(estimator, X, y,  fit_params={'sample_weight':sample_weight}, cv=cv)\n",
    "        score, score_err = scores.mean(), sp.stats.sem(scores)\n",
    "\n",
    "        if verbose: print_progress_bar(18)\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        estimator.fit(X, y, sample_weight=sample_weight)\n",
    "        estimators.append(estimator)\n",
    "        benchmarks.append(('Random Forest natively handling it', scores, time.time() - start))\n",
    "\n",
    "        if verbose: print_progress_bar(20)\n",
    "\n",
    "\n",
    "\n",
    "        # 2) Estimate score after mean imputation of missing values without indicator features\n",
    "        estimator = Pipeline([(\"Impute\", Imputer(missing_values=\"NaN\", strategy=\"mean\",\n",
    "                                                 add_indicator_features=False, axis=0)),\n",
    "                              (\"rf\", RandomForestClassifier(random_state=0, bootstrap=bootstrap,\n",
    "                                                            n_jobs=n_jobs, n_estimators=n_estimators,\n",
    "                                                            max_depth=max_depth))])\n",
    "        scores = cross_val_score(estimator, X, y, fit_params={'rf__sample_weight':sample_weight}, cv=cv)\n",
    "        score, score_err = scores.mean(), sp.stats.sem(scores)\n",
    "\n",
    "        if verbose: print_progress_bar(38)\n",
    "\n",
    "        start = time.time()\n",
    "        estimator.fit(X, y, rf__sample_weight=sample_weight)\n",
    "        estimators.append(estimator)\n",
    "        benchmarks.append(('mean imputation of the missing values', scores, time.time() - start))\n",
    "\n",
    "        if verbose: print_progress_bar(40)\n",
    "\n",
    "\n",
    "\n",
    "        # 3) Estimate score after mean imputation of the missing values with indicator matrix\n",
    "        estimator = Pipeline([(\"Impute\", Imputer(missing_values=\"NaN\", strategy=\"mean\",\n",
    "                                                 add_indicator_features=True, axis=0)),\n",
    "                              (\"rf\", RandomForestClassifier(random_state=0, bootstrap=bootstrap,\n",
    "                                                             n_jobs=n_jobs, n_estimators=n_estimators,\n",
    "                                                             max_depth=max_depth))])\n",
    "        scores = cross_val_score(estimator, X, y, fit_params={'rf__sample_weight':sample_weight}, cv=cv)\n",
    "        score, score_err = scores.mean(), sp.stats.sem(scores)\n",
    "\n",
    "        if verbose: print_progress_bar(58)\n",
    "\n",
    "        start = time.time()\n",
    "        estimator.fit(X, y, rf__sample_weight=sample_weight)\n",
    "        estimators.append(estimator)\n",
    "        benchmarks.append(('mean imputation of the missing values w/indicator features', scores, time.time() - start))\n",
    "\n",
    "        if verbose: print_progress_bar(60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 4) Estimate score after median imputation of missing values without indicator features\n",
    "        estimator = Pipeline([(\"Impute\", Imputer(missing_values=\"NaN\", strategy=\"median\",\n",
    "                                                 add_indicator_features=False, axis=0)),\n",
    "                              (\"rf\", RandomForestClassifier(random_state=0, bootstrap=bootstrap,\n",
    "                                                             n_jobs=n_jobs, n_estimators=n_estimators,\n",
    "                                                             max_depth=max_depth))])\n",
    "        scores = cross_val_score(estimator, X, y, fit_params={'rf__sample_weight':sample_weight}, cv=cv)\n",
    "        score, score_err = scores.mean(), sp.stats.sem(scores)\n",
    "\n",
    "        if verbose: print_progress_bar(78)\n",
    "\n",
    "        start = time.time()\n",
    "        estimator.fit(X, y, rf__sample_weight=sample_weight)\n",
    "        estimators.append(estimator)\n",
    "        benchmarks.append(('median imputation of the missing values', scores, time.time() - start))\n",
    "\n",
    "        if verbose: print_progress_bar(80)\n",
    "\n",
    "\n",
    "        # 5) Estimate score after median imputation of the missing values with indicator matrix\n",
    "        estimator = Pipeline([(\"Impute\", Imputer(missing_values=\"NaN\", strategy=\"median\",\n",
    "                                                 add_indicator_features=True, axis=0)),\n",
    "                              (\"rf\", RandomForestClassifier(random_state=0, bootstrap=bootstrap,\n",
    "                                                            n_jobs=n_jobs, n_estimators=n_estimators,\n",
    "                                                            max_depth=max_depth))])\n",
    "        scores = cross_val_score(estimator, X, y, fit_params={'rf__sample_weight':sample_weight}, cv=cv)\n",
    "        score, score_err = scores.mean(), sp.stats.sem(scores)\n",
    "\n",
    "        if verbose: print_progress_bar(98)\n",
    "\n",
    "        start = time.time()\n",
    "        estimator.fit(X, y, rf__sample_weight=sample_weight)\n",
    "        estimators.append(estimator)\n",
    "        benchmarks.append(('median imputation of the missing values w/indicator features',\n",
    "                           scores, time.time() - start))\n",
    "\n",
    "\n",
    "        if verbose: print_progress_bar(100)\n",
    "\n",
    "\n",
    "        names, scores, times = list(zip(*benchmarks))\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        ## Per estimator/technique, compute the ranks based on the score per fold \n",
    "        #ranks = np.array(list(rankdata(scores[:, i], method='min') for i in range(scores.shape[1]))).T\n",
    "        #ranks_score = rankdata(ranks.mean(axis=1), method='min')\n",
    "\n",
    "        scores = scores.mean(axis=1)\n",
    "        ranks_score = rankdata(-scores, method='min')\n",
    "        #print(ranks_score)\n",
    "        ranks_fit_time = rankdata(times, method='min')\n",
    "\n",
    "        all_benchmarks[dataset_desc] = benchmarks\n",
    "        all_estimators[dataset_desc] = estimators\n",
    "        all_score_ranks[dataset_desc] = ranks_score\n",
    "        all_time_ranks[dataset_desc] = ranks_fit_time\n",
    "\n",
    "        if verbose:\n",
    "            # Print statistics for this dataset\n",
    "            for i, benchmark in enumerate(benchmarks):\n",
    "                print(\"%s Got a score of %0.8f [%s] with %s (Train time %0.2fs [%s] %s)\"\n",
    "                      % (\"*\" if ranks_score[i] == 1 else \" \",\n",
    "                         benchmark[1].mean(), ranks_score[i], benchmark[0],\n",
    "                         benchmark[2], ranks_fit_time[i],\n",
    "                         \"*\" if ranks_fit_time[i] == 1 else \" \"))\n",
    "        \n",
    "            \n",
    "    # After all the datasets print the summary for one set of parameters\n",
    "    print(\"Benchmark summary\")\n",
    "    print(\"=================\")\n",
    "    if verbose:\n",
    "        print(\"n_estimators=%d; max_depth=%s; bootstrap=%s\" % (n_estimators, str(max_depth), str(bootstrap)))\n",
    "\n",
    "\n",
    "    methods = list(zip(*next(iter(all_benchmarks.values()))))[0]\n",
    "    n_methods = len(methods)\n",
    "\n",
    "    n_datsets = len(all_benchmarks)\n",
    "    rank_suffix = [None, 'st', 'nd', 'rd', 'th', 'th']\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n%d datasets were tested.\\n\\nn_estimators=%d and \\ncv=%s\" \n",
    "              % (n_datsets, n_estimators, str(cv)))\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    score_ranks_per_method = list(zip(*list(all_score_ranks.values())))\n",
    "    _bincount_ = partial(np.bincount, minlength=n_methods + 1)\n",
    "    bincount_score_ranks_per_method = list(map(_bincount_, score_ranks_per_method))\n",
    "    fittime_ranks_per_method = list(zip(*list(all_time_ranks.values())))\n",
    "    bincount_fittime_ranks_per_method = list(map(_bincount_, fittime_ranks_per_method))\n",
    "\n",
    "    if verbose:\n",
    "        print('-' * 100)\n",
    "        for i, method in enumerate(methods):\n",
    "            print(method, '\\n')\n",
    "\n",
    "            score_rank_counts = bincount_score_ranks_per_method[i][1:]\n",
    "            time_rank_counts = bincount_fittime_ranks_per_method[i][1:]\n",
    "\n",
    "            rank_stats = \"\".join((\"%d%s (%d / %d times) \"\n",
    "                                  %  (r, rank_suffix[r], score_rank_counts[r-1], n_datsets))\n",
    "                                  for r in range(1, 6))\n",
    "            print(\"--> got ranked by score \\n - %s\" % (rank_stats))\n",
    "            print()\n",
    "            rank_stats = \"\".join((\"%d%s (%d / %d times) \"\n",
    "                                  %  (r, rank_suffix[r], time_rank_counts[r-1], n_datsets))\n",
    "                                  for r in range(1, 6))\n",
    "            print(\"--> got ranked by lower fit-time on entire dataset \\n - %s\" % (rank_stats))\n",
    "            print()\n",
    "\n",
    "            print('-' * 100)\n",
    "    \n",
    "    \n",
    "    # Plot histogram of ranks\n",
    "\n",
    "    # ind = np.array([1, 1.3, 1.6, 1.9, 2.2])  # the x locations for the groups\n",
    "    ind = np.array([1, 2.5, 4, 5.5, 7])\n",
    "    width = 0.2       # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    fig.set_size_inches(10, 15)\n",
    "\n",
    "    colors = ['r', 'g', 'b', 'k', 'y']\n",
    "\n",
    "    rects1, rects2 = [], []\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "        this_scores = bincount_score_ranks_per_method[i][1:]\n",
    "        this_times = bincount_fittime_ranks_per_method[i][1:]\n",
    "        score_rank_counts = np.hstack((np.cumsum(this_scores[:-1]), this_scores[-1]))\n",
    "        time_rank_counts = np.hstack((np.cumsum(this_times[:-1]), this_times[-1]))\n",
    "\n",
    "        #  ((width + 0.1) * 5 + 0.5) * i\n",
    "        rects1.append(ax[0].bar(ind + width * i,\n",
    "                                score_rank_counts, width, color=colors[i]))\n",
    "        rects2.append(ax[1].bar(ind + width * i,\n",
    "                                time_rank_counts, width, color=colors[i]))\n",
    "\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax[0].set_ylabel('Number of Datasets')\n",
    "    ax[0].set_xlabel('(Bins of Ranks)')\n",
    "\n",
    "    ax[0].set_title('Score rank statistics\\n(Higher score ranks lower)\\n')\n",
    "    ax[0].set_xticks(ind + width * 2.5)\n",
    "    # ax[0].set_xticklabels(('1', '2', '3', '4', '5'))\n",
    "    ax[0].set_xticklabels(('Ranked Best', 'Ranked 1st or 2nd', '1st 2nd or 3rd', '1st 2nd 3rd or 4th', 'Ranked Worst'))\n",
    "    ax[0].set_ylim((-0.5, n_datsets + 1))\n",
    "\n",
    "    ax[1].set_title('Fit time rank statistics\\n(faster ranks lower)\\n')\n",
    "    ax[1].set_xlabel('(Bins of Ranks)')\n",
    "    ax[1].set_xticks(ind + width * 2.5)\n",
    "    ax[1].set_xticklabels(('Ranked Best', 'Ranked 1st or 2nd', '1st 2nd or 3rd', '1st 2nd 3rd or 4th', 'Ranked Worst'))\n",
    "    ax[1].set_ylim((-0.5, n_datsets + 1))\n",
    "\n",
    "\n",
    "    def autolabel(rects, ax):\n",
    "        # attach some text labels\n",
    "        for bars in rects:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        '%d' % int(height),\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1, ax[0])\n",
    "    autolabel(rects2, ax[1])\n",
    "\n",
    "    ax[1].legend(rects1, methods, bbox_to_anchor=(0.1, 2.7), loc='upper left')\n",
    "\n",
    "    #ax[1].title(\"Comparison of performance of various methods of handling missing values.\\nn_estimators=10, mean across 20 Stratified Shuffle Splits with 0.2 test size\")\n",
    "\n",
    "    plt.show()\n",
    "    print('=' * 100)\n",
    "    print()\n",
    "    \n",
    "    all_results[(n_estimators, max_depth, bootstrap)] = (all_benchmarks, all_score_ranks,\n",
    "                                                         all_time_ranks, all_estimators)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
